{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ff2f31",
   "metadata": {},
   "source": [
    "<img style=\"max-width:20em; height:auto;\" src=\"../graphics/A-Little-Book-on-Adversarial-AI-Cover.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a5a33",
   "metadata": {},
   "source": [
    "Author: Nik Alleyne   \n",
    "Author Blog: https://www.securitynik.com   \n",
    "Author GitHub: github.com/securitynik   \n",
    "\n",
    "Author Other Books: [   \n",
    "\n",
    "            \"https://www.amazon.ca/Learning-Practicing-Leveraging-Practical-Detection/dp/1731254458/\",   \n",
    "            \n",
    "            \"https://www.amazon.ca/Learning-Practicing-Mastering-Network-Forensics/dp/1775383024/\"   \n",
    "        ]   \n",
    "\n",
    "\n",
    "This notebook ***(knockoff-nets-white-box.ipynb)*** is part of the series of notebooks From ***A Little Book on Adversarial AI***  A free ebook released by Nik Alleyne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f83f60",
   "metadata": {},
   "source": [
    "## KnockOff Nets White-box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d66414",
   "metadata": {},
   "source": [
    "### Lab Objectives:   \n",
    "- Learn how to use Adversarial Robustness Toolkit (ART) for white-box attacks \n",
    "- How to create copy of a model when you have access to the model  \n",
    "- Understand that it takes a large number of query to be able to achieve this attack   \n",
    "- Understand what knock-off nets are  \n",
    "- If you wish build on this concept for copy-cat nets  \n",
    "\n",
    "\n",
    "### Step 1:  \n",
    "Obtaining the pre-trained model   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40d9e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries that we will need\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# This is for Adversarial Robustness Toolkit usage\n",
    "import art\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.extraction import KnockoffNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b107a1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version used:  2.7.1+cu128\n",
      "ART version used:  1.20.1\n"
     ]
    }
   ],
   "source": [
    "### Version of key libraries used  \n",
    "print(f'Torch version used:  {torch.__version__}')\n",
    "print(f'ART version used:  {art.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed586e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the device to cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup the device to work with\n",
    "# This should ensure if there are accelerators in place, such as Apple backend or CUDA, \n",
    "# we should be able to take advantage of it.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Setting the device to cuda')\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    print('Setting the device to Apple mps')\n",
    "    device = 'mps'\n",
    "else:\n",
    "    print('Setting the device to CPU')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f2f604",
   "metadata": {},
   "source": [
    "Earlier in the notebookbook **mal_net_tiny_malware_classification_multi_class.ipynb**, we created the malware classifier for the Tiny Mal Net Malware dataset. Let us target that classifier. \n",
    "\n",
    "Realistically, in the real-world via a black-box attack, you will not have access to the model this way. You would instead interact with the model via an API. We will do that shortly. However, for now, as we have the model, let us use it this way also, to build our understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "095b3005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=MalClassifier\n",
       "  (conv_layers): RecursiveScriptModule(\n",
       "    original_name=Sequential\n",
       "    (0): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "    (2): RecursiveScriptModule(original_name=ReLU)\n",
       "    (3): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (4): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "    (5): RecursiveScriptModule(original_name=ReLU)\n",
       "    (6): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (7): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "    (8): RecursiveScriptModule(original_name=ReLU)\n",
       "  )\n",
       "  (global_avg_pool): RecursiveScriptModule(original_name=AdaptiveAvgPool2d)\n",
       "  (classifier): RecursiveScriptModule(original_name=Conv2d)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the victim model\n",
    "loaded_victim_model = torch.jit.load(f=r'../data/mal_net_tiny_malware_clf.jit', map_location=device)\n",
    "loaded_victim_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10bc89",
   "metadata": {},
   "source": [
    "Let us start off with the assumption that we know that for virus detection, we can use Convolutional Network. From this perspective, we can build a Convolutional Network to try to mimic the real network which we do not have.\n",
    "\n",
    "Note: Let us be clear, there is nothing that states that malware detection has to be done via Convoluational Neural Networks. In fact, you can use any architecture. Also in the **bodmas_malware_classifier.ipynb** we used linear layers. At the same time, you could use Gradient Boosting as was used in the BODMAS paper, or even Graphh Neural Networks that is used by MalNet also. So keep in mind, we are working with a fair assumption in our case but it is just that, an assumption.\n",
    "\n",
    "Our scenario here, is that we have an API endpoint that predicts whether a file hash is malicious or not. We could even consider the VirusTotal interface as an example \n",
    "\n",
    "<img style=\"max-width:50em; height:auto;\" src=\"../graphics/virustotal_file_hash.png\"/>\n",
    "\n",
    "\n",
    "We know that the endpoint expects a SHA-256 hash. We could get a set of files generate the hash and feed each one to the end point. In our Linux shell, we could do something such as:  \n",
    "$ **sha256sum /tmp/tiny_mal_net_X_y_t** \n",
    "*c721f56288747a5d7b23a3589112379eed129d0d0d37256b6bbb531c6c7e2348  /tmp/tiny_mal_net_X_y_test.npz*   \n",
    "*3772630f57c89a15f6b6924ff1ce5ff1d1f15df6d4b348e8e8e4e5363720b961  /tmp/tiny_mal_net_X_y_train.npz*    \n",
    "  \n",
    "However, even with these hashes, we still need to get the values as 0 or 1. This is because as we saw earlier when constructing the model, that the hash is preprocessed as a set of 0s and 1s and this is what is provided to the model. We also learnt, that in the paper on Copycat CNNs, they used random natural images, https://arxiv.org/pdf/1806.05476. We can create the same by either generating vectors of random 0s and 1 or random hashes.   \n",
    "\n",
    "### Step 2:   \n",
    "Get the data, via random generation of file hashes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f6a5577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789ABCDEF'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get our sample data\n",
    "# Setup a variable for the values in the hex character set\n",
    "# Remember, Hex can go from 0-9 in numbers and A-F in letters\n",
    "possible_hex_values = '0123456789ABCDEF'\n",
    "possible_hex_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f822e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import more libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd8282b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1DF06EF851FA27B1D4BCD98E59B4E7EC107469B7AEDF2A57D711F9224CB433E5'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a random seed to ensure we both have the same results\n",
    "random.seed(10)\n",
    "\n",
    "# Generate a random SHA256 hash string using our character set which was defined above\n",
    "sample_hash = ''.join(random.choice(possible_hex_values) for _ in range(64) )\n",
    "\n",
    "# here is a sample hash we randomly generate\n",
    "sample_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "554976f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now update this to generate a batch of 10 samples\n",
    "# Putting everything in a function, so we can call this anytime we wish\n",
    "\n",
    "def generate_hashes(batch_size:int=10, hash_length=64):\n",
    "    '''\n",
    "    Takes the number of samples to be generated and the length of the hash\n",
    "\n",
    "    Args:\n",
    "        batch_size (int):  The number of items in the bash\n",
    "        hash_length (int): default to SHA-256 but if you wish to use MD5, or SHA256, this can easily be changed\n",
    "    \n",
    "    '''\n",
    "    batches = []\n",
    "\n",
    "    for _ in range(batch_size):\n",
    "        batches.append(''.join(random.choice(possible_hex_values) for _ in range(hash_length) ))\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f11cdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['483A50DD234AFED66AAAD2FC267163268998530877710984AE48D55C34DB7316',\n",
       " 'D552390ACE153EA0232A8291067050494D83C36767394C42EF0569C396B94308',\n",
       " '1CB9CE32F602A058930166C2B9E14CCC80E2FA769EAC61B42B03F74904BB407D',\n",
       " 'E7CC992F8B4E7F4BA43816BC69F5448025A87A24883492F11FFC349D5EEF4566',\n",
       " '936ECE29366969DF3B75B940AC49425138D26EED1553F9578733EDA751E20908',\n",
       " 'B89C2B015572ED106CE29E9A3E6431B565790317DC8A4A102F546B449359E623',\n",
       " '404B9B080E0A9FE9101209D8E82D20C08020A3FD3A00317E7BB23278EEF11E25',\n",
       " '56767914BEAEF093B6945178510363FE871D79A97BFD2666FEA4EC204F61F803',\n",
       " 'E1730427C0A688A67D1807EADAB22CF584241473062A71F74C3E861AC2DEDD37',\n",
       " '7A30601A5DA17489F93A27E7906C362ECFD6424CF1E72CA22B4611740348FD85']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are setting the seed here, so we can ensure consistency across our work\n",
    "seed = 20\n",
    "\n",
    "# Generate some hashes using our function\n",
    "random.seed(seed)\n",
    "sample_hashes = generate_hashes()\n",
    "sample_hashes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8e8e9f",
   "metadata": {},
   "source": [
    "At this point we know how to generate some random hashes. For learning purposes, let's say that the application accepting the hashes then does the preprocessing into bits. Let's create a function to simulate that process.\n",
    "\n",
    "Now that we know how to do those things, we should create a function to transform the hex values to bits.  This is basically the same steps as done above, now consolidated as a function. We will return the bits as well as the labels encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8dd9736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the hashes to bits\n",
    "def create_bits_from_hex_string(hash=None) -> np.array:\n",
    "    bits_list = []\n",
    "    \n",
    "    hex_string_splitted = [[ hex_string[i:i+2] for i in range(0, len(hex_string), 2) ] for  hex_string in hash]\n",
    "\n",
    "    # Create a for loop to perform the task we just did above\n",
    "    for item in hex_string_splitted:\n",
    "        bits_list.append(list(''.join([ np.binary_repr(int(i, base=16), width=8) for i in item])))\n",
    "\n",
    "    # The data in the bit_list comes in the form of strings as can been seen previously\n",
    "    # Let's get this as float vlaues by setting the dtype=np.float32\n",
    "    return np.array(bits_list, dtype=np.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd6426a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 1., 0., ..., 1., 1., 0.],\n",
       "        [1., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 1.],\n",
       "        ...,\n",
       "        [0., 1., 0., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [0., 1., 1., ..., 1., 0., 1.]], dtype=float32),\n",
       " (10, 256))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As always setting a seed so that our results can be deterministic\n",
    "seed = 20\n",
    "random.seed(seed)\n",
    "raw_bits = create_bits_from_hex_string(hash=sample_hashes)\n",
    "raw_bits[:10], raw_bits.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85ff839f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "           0.],\n",
       "          [0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "           1.],\n",
       "          [0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "           0.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "           0.],\n",
       "          [0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "           0.],\n",
       "          [1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "           0.],\n",
       "          [0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "           1.],\n",
       "          [0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "           0.],\n",
       "          [1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
       "           0.],\n",
       "          [0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0.],\n",
       "          [0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "           1.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "           0.],\n",
       "          [1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "           0.],\n",
       "          [1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
       "           0.],\n",
       "          [0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "           1.],\n",
       "          [0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "           0.]]]], dtype=float32),\n",
       " (10, 1, 16, 16))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These bits now needs to be reshaped to reflect the expected input to the network\n",
    "# The expected input is batch, channels, height and width.\n",
    "# Hence for our problem this is batch (-1), channels (1) because it is a black and white image, height (16) pixels, width (16) pixels\n",
    "raw_bits = raw_bits.reshape(-1, 1, 16, 16)\n",
    "raw_bits[:1], raw_bits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97475349",
   "metadata": {},
   "source": [
    "- At this point, I should state, rather than generating those hashes, we could have started with the above as our input.   \n",
    "- The model ultimately expects an image, hence this last step above was a good place to start.   \n",
    "- However, it is important that we understand preprocessing our data. You have to ensure the same preprocessing steps used to train the model is followed at time of prediction   \n",
    "- To get the 1s and 0s as in above, we could have done:    \n",
    "np.random.randint(low=0, high=2, size=(10, 1, 16, 16))   \n",
    "\n",
    "\n",
    "array([[[[1, 0, 0, ..., 0, 0, 1],  \n",
    "        [1, 0, 1, ..., 0, 1, 1],  \n",
    "        [0, 0, 1, ..., 0, 0, 0],  \n",
    "        ...,  \n",
    "        [0, 1, 0, ..., 0, 1, 1],  \n",
    "        [1, 0, 1, ..., 1, 0, 0],  \n",
    "        [0, 1, 0, ..., 0, 0, 1]]],  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a36bd4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's consolidate these two steps into one function\n",
    "def create_model_input(batch_size:int=10, hash_length:int=64):\n",
    "    sample_hashes = generate_hashes(batch_size=batch_size, hash_length=hash_length)\n",
    "    raw_bits = create_bits_from_hex_string(hash=sample_hashes)\n",
    "    return raw_bits.reshape(-1, 1, 16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4119d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "           0.],\n",
       "          [0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "           1.],\n",
       "          [0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "           0.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "           0.],\n",
       "          [0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "           0.],\n",
       "          [1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "           0.],\n",
       "          [0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "           1.],\n",
       "          [0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "           0.],\n",
       "          [1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
       "           0.],\n",
       "          [0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0.],\n",
       "          [0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "           1.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "           0.],\n",
       "          [1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "           0.],\n",
       "          [1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
       "           0.],\n",
       "          [0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "           1.],\n",
       "          [0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "           0.]]]], dtype=float32),\n",
       " (1000, 1, 16, 16))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the consolidation function\n",
    "seed = 20\n",
    "random.seed(seed)\n",
    "X_hashes = create_model_input(batch_size=1000)\n",
    "X_hashes[:1], X_hashes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd06b75",
   "metadata": {},
   "source": [
    "### Step 3:   \n",
    "Making predictions via the local model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70208689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.672586  ,  2.5005682 , -4.7138033 , -0.2533269 , -7.612843  ],\n",
       "        [-4.434322  , -1.2528257 ,  2.796306  , -4.5251966 ,  1.1526    ],\n",
       "        [ 0.6579074 ,  1.5752946 , -3.8772795 , -1.4706458 , -3.8419905 ],\n",
       "        [ 2.9383914 , -2.9466214 , -0.04146989, -1.3981977 , -5.440143  ],\n",
       "        [-5.7621484 ,  0.3885756 , -1.2469345 , -1.6378592 ,  0.7337332 ]],\n",
       "       dtype=float32),\n",
       " (1000, 5))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With this data, let us now make predictions on this batch. \n",
    "# This is just sanity check to ensure everything is working as expected so far\n",
    "y_logits = loaded_victim_model(torch.as_tensor(data=X_hashes, dtype=torch.float32, device=device)).detach().cpu().numpy()\n",
    "\n",
    "# With the results returned, we are now able to see the first 5 logits returned\n",
    "y_logits[:5], y_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcb17ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4]), array([187, 207, 195, 210, 201]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a glimpse at the diversity of the model's predictions\n",
    "np.unique(np.argmax(y_logits, axis=-1), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c70e36",
   "metadata": {},
   "source": [
    "Looks like our victim model is ready to be attacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59b14ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capture the number of classes from this model\n",
    "nb_classes = y_logits.shape[1]\n",
    "nb_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c69efd",
   "metadata": {},
   "source": [
    "### Step 4:  \n",
    "Setting up our **knockoff_model**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adba6854",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "\n",
    "# The number of filters is immediately different from what the original network had\n",
    "num_filters = 64\n",
    "\n",
    "# The victim model does not have a linear layer at the end\n",
    "linear_out = 256\n",
    "\n",
    "# With this  model we would like to learn the parameters from the victim model\n",
    "# Noticed immediately that the architecture is different from or victim model \n",
    "\n",
    "knockoff_model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(3, 3), stride=1, padding=1, padding_mode='zeros'),\n",
    "    # Notice that we do not have a batch normalization layer as in the original model\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Conv2d(in_channels=num_filters, out_channels=num_filters*2, kernel_size=(3, 3), stride=1, padding=1, padding_mode='zeros'),\n",
    "    # Notice that we do not have a batch normalization layer as in the original model\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Conv2d(in_channels=num_filters*2, out_channels=num_filters*3, kernel_size=(3, 3), stride=1, padding=1, padding_mode='zeros'),\n",
    "    # Notice that we do not have a batch normalization layer as in the original model\n",
    "    nn.ReLU(),\n",
    "\n",
    "    # Notice now the introduction of the flatten layer followed by linear layers\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "\n",
    "    # Remember, the image is 16*16 and the last convolution layer pushed out 32*2 filters. Hence the 64\n",
    "    nn.Linear(in_features=16*16*num_filters*3, out_features=linear_out * 4, bias=True),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    # Ths is is new when compared to the original model\n",
    "    nn.Linear(in_features=linear_out * 4, out_features=nb_classes, bias=True),  # 5 here rerpresents the number of classes that came out of the testing above\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "229ec554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    decoupled_weight_decay: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(params=knockoff_model.parameters(), lr=0.001)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70d4f0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" for i in range(100):\\n    optimizer.zero_grad(set_to_none=True)\\n    loss = loss_fn(knockoff_model(torch.as_tensor(X_hashes, dtype=torch.float32)), torch.as_tensor(y_tmp, dtype=torch.long))\\n    loss.backward()\\n    optimizer.step()\\n\\n    if (i + 1) % 10 == 0:\\n        print(f'Epoch: {i+1}/100 \\t loss: {loss.item()}')\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just verifying this model can learn from this data\n",
    "# If you wish to see this in action, just remove the comments\n",
    "\"\"\" for i in range(100):\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss = loss_fn(knockoff_model(torch.as_tensor(X_hashes, dtype=torch.float32)), torch.as_tensor(y_tmp, dtype=torch.long))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f'Epoch: {i+1}/100 \\t loss: {loss.item()}')\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08141244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you wish to see the distribution of the classes predicted from above uncomment below\n",
    "# Remember to uncomment and run above first\n",
    "# np.unique(knockoff_model(torch.as_tensor(X_hashes)).detach().numpy().argmax(axis=-1), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "664070a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you wish to see the model's accuracy, uncomment below\n",
    "# Remember to uncomment the two previous cells\n",
    "# (knockoff_model(torch.as_tensor(X_hashes)).detach().numpy().argmax(axis=-1) == y_tmp).sum() / y_tmp.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a5bdd",
   "metadata": {},
   "source": [
    "### Step 5:  \n",
    "Creating the ART attack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b84da977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get to work\n",
    "# Create the classifier to mimic the victim model\n",
    "# Remember, this model would like to learn the parameters from the victim model\n",
    "# PyTorchClassifier is from ART\n",
    "\n",
    "knockoff_classifier = PyTorchClassifier( \n",
    "    model=knockoff_model,  # Our knockoff model\n",
    "    loss=loss_fn,   # Measures how well the model is performing\n",
    "    input_shape=X_hashes.shape[1:], \n",
    "    nb_classes=nb_classes, \n",
    "    optimizer=optimizer, \n",
    "    device_type=device)\n",
    "\n",
    "# knockoff_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcd28874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the victim classifier using ART\n",
    "# Remember, for this scenario, we have access to the victim modem via the loaded_victim_model variable above\n",
    "# https://adversarial-robustness-toolbox.readthedocs.io/en/latest/modules/estimators/classification.html\n",
    "victim_classifier = PyTorchClassifier(\n",
    "    model=loaded_victim_model, # This is the victim model we loaded at the beginning.\n",
    "    loss=nn.CrossEntropyLoss(), \n",
    "    input_shape=X_hashes.shape[1:], \n",
    "    nb_classes=nb_classes,\n",
    "    optimizer=torch.optim.Adam(params=loaded_victim_model.parameters(), lr=0.001), \n",
    "    device_type=device,\n",
    "    )\n",
    "\n",
    "# Uncomment this line below if you would like to see the ART information for this model\n",
    "#victim_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfb47910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnockoffNets(batch_size_fit=32, batch_size_query=32, nb_epochs=10, nb_stolen=2000, sampling_strategy=adaptive, reward=all, verbose=True, use_probability=False, )"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define our knockoff-net attack\n",
    "# https://adversarial-robustness-toolbox.readthedocs.io/en/latest/modules/attacks/extraction.html#knockoff-nets\n",
    "\n",
    "knockoffnets_attack = KnockoffNets(\n",
    "    classifier=victim_classifier,  # Victim classifier that we are attempting to steal\n",
    "    batch_size_fit=32, \n",
    "    batch_size_query=32, \n",
    "    nb_epochs=10,  # Number of epochs used for training\n",
    "    nb_stolen=2000, # number of queries to submit to the victim, in order to steal it\n",
    "    sampling_strategy='adaptive',  # The sampling strategy to use. if the classes are severly imbalanced, you should instead use 'random'\n",
    "    reward='all', \n",
    "    verbose=True, \n",
    "    use_probability=False)\n",
    "knockoffnets_attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb786e4",
   "metadata": {},
   "source": [
    "### Step 6:  \n",
    "Generating the adversarial examples   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b76ba996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1789755d9d4d6d9385b00e513f15f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Knock-off nets:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "art.estimators.classification.pytorch.PyTorchClassifier(model=ModelWrapper(\n",
       "  (_model): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    (7): Linear(in_features=49152, out_features=1024, bias=True)\n",
       "    (8): ReLU()\n",
       "    (9): Linear(in_features=1024, out_features=5, bias=True)\n",
       "  )\n",
       "), loss=CrossEntropyLoss(), optimizer=Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    decoupled_weight_decay: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       "), input_shape=(1, 16, 16), nb_classes=5, channels_first=True, clip_values=None, preprocessing_defences=None, postprocessing_defences=None, preprocessing=StandardisationMeanStdPyTorch(mean=0.0, std=1.0, apply_fit=True, apply_predict=True, device=cuda:0))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform the model extraction using the knock off net\n",
    "# The thieved_classifier below, is the knockoff_classifier that we defined above. \n",
    "# This is our network which has to learn the parameters of the victim model \n",
    "# Depending on your system based on the configuration above, this will take just about 30 minutes to finish\n",
    "\n",
    "knockoff_model = knockoffnets_attack.extract(x=X_hashes, y=y_logits, thieved_classifier=knockoff_classifier)\n",
    "knockoff_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c651d43",
   "metadata": {},
   "source": [
    "### Step 7:   \n",
    "Make predictions on the adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "445b6ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The knockoff model accuracy is: 0.562\n"
     ]
    }
   ],
   "source": [
    "# Make some predictions using our original data against the trained knockoff_model\n",
    "knockoff_model_preds = knockoff_model.predict(x=X_hashes)\n",
    "\n",
    "# Get the accuracy now, using the knockoff model's predictions vis the original logits which we obtained earlier\n",
    "knockoff_accuracy = (y_logits.argmax(axis=-1) == knockoff_model_preds.argmax(axis=-1)).sum() / y_logits.shape[0]\n",
    "\n",
    "print(f'The knockoff model accuracy is: {knockoff_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "728202dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning cuda cache\n"
     ]
    }
   ],
   "source": [
    "# With the training finish clear the GPU cache\n",
    "# Setup the device to work with\n",
    "if torch.cuda.is_available():\n",
    "    # For CUDA GPU\n",
    "    print(f'Cleaning {device} cache')\n",
    "    torch.cuda.empty_cache()\n",
    "elif torch.backends.mps.is_available():\n",
    "    # For Apple devices\n",
    "    print(f'Cleaning {device} cache')\n",
    "    torch.mps.empty_cache()\n",
    "else:\n",
    "    # Default to cpu\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c3598f",
   "metadata": {},
   "source": [
    "### That's it for knockoff nets in the white-box setting! \n",
    "\n",
    "### Takeaways   \n",
    "- We were able to leverage ART for a model we had direct access to \n",
    "- However, in the real world, we more than likely will not have access to the model. \n",
    "- See you in the next lab, where we look at this from the black-box perspective. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d1a355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb5bbfb9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f621b62e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adversarial_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
