{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeeca178",
   "metadata": {},
   "source": [
    "<img style=\"max-width:20em; height:auto;\" src=\"../graphics/A-Little-Book-on-Adversarial-AI-Cover.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05d0820",
   "metadata": {},
   "source": [
    "Author: Nik Alleyne   \n",
    "Author Blog: https://www.securitynik.com   \n",
    "Author GitHub: github.com/securitynik   \n",
    "\n",
    "Author Other Books: [   \n",
    "\n",
    "            \"https://www.amazon.ca/Learning-Practicing-Leveraging-Practical-Detection/dp/1731254458/\",   \n",
    "            \n",
    "            \"https://www.amazon.ca/Learning-Practicing-Mastering-Network-Forensics/dp/1775383024/\"   \n",
    "        ]   \n",
    "\n",
    "\n",
    "This notebook ***(dataset_dataloader.ipynb)*** is part of the series of notebooks From ***A Little Book on Adversarial AI***  A free ebook released by Nik Alleyne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf0b108",
   "metadata": {},
   "source": [
    "### Custom DataSet and DataLoader\n",
    "When building machine learning models, we often work with very large datasets. In many cases, those datasets cannot be loaded directly into memory. If we try to load these large datasets into memory, we get an **out of memory error**.   \n",
    "  \n",
    "To address this concern, datasets are used in conjunction with data loaders. Let's build a simple dataset and use with a dataloader to process this information.   \n",
    "\n",
    "Think of the dataset as a container for our data that has a length and is indexable.   \n",
    "References:   https://www.intodeeplearning.com/how-to-use-pytorch-dataloader/    \n",
    "\n",
    "\n",
    "### Lab Objectives:   \n",
    "- Learn how to create a dataset \n",
    "- Learn the key components of a dataset\n",
    "- Learn how to use a dataset\n",
    "- Leverage a dataloader  \n",
    "- Understand the role the dataloader play when working with \n",
    "\n",
    "\n",
    "### Step 1:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "392bf743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start this process off by importing the Dataloader and Dataset class\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f144c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version used:  2.7.1+cu128\n"
     ]
    }
   ],
   "source": [
    "### Version of key libraries used  \n",
    "print(f'Torch version used:  {torch.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c65e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the device to cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup the device to work with\n",
    "# This should ensure if there are accelerators in place, such as Apple backend or CUDA, \n",
    "# we should be able to take advantage of it.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Setting the device to cuda')\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    print('Setting the device to Apple mps')\n",
    "    device = 'mps'\n",
    "else:\n",
    "    print('Setting the device to CPU')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e599eb7a",
   "metadata": {},
   "source": [
    "Let's go ahead and now create a sample dataset by *subclassing* the Dataset class. In subclassing, the Dataset class, we need to ensure our class has two key items. These are:   \n",
    "- The **__len__** : This returns the number of samples in the dataset\n",
    "- the **__getitem__** : Load and return a sample from the batch at a given index position   \n",
    "https://tanelp.github.io/posts/a-bug-that-plagues-thousands-of-open-source-ml-projects/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6623f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MyFirstDataSet by subclassing dataset\n",
    "class MyFirstDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        # Define a variable called X\n",
    "        self.X = X\n",
    "\n",
    "    # Define here the index of the item to be returned\n",
    "    def __getitem__(self, index):\n",
    "        # Take the input from X and index into the rows\n",
    "        return index, self.X[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Get the total number of samples in the dataset\n",
    "        return self.X.shape[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be8b1a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[937., 405.],\n",
       "         [932., 567.],\n",
       "         [432., 705.],\n",
       "         [187.,  92.],\n",
       "         [321., 805.],\n",
       "         [256., 773.],\n",
       "         [521., 210.],\n",
       "         [536., 833.],\n",
       "         [504., 610.],\n",
       "         [616.,  22.]]),\n",
       " torch.Size([10, 2]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create some sample data\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# Modify this as you wish\n",
    "# Create more rows or columns by adjusting the size=(10,2)\n",
    "# To for example size=(20,4), etc.\n",
    "X = torch.randint(low=0, high=1000, dtype=torch.float, size=(10,2))\n",
    "\n",
    "# Take a peak at the data \n",
    "# At the same time return the size/shape\n",
    "X, X.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dc43fd",
   "metadata": {},
   "source": [
    "Instantiate the class  \n",
    "\n",
    "### Step 2:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3a69dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataset is: 10\n",
      "The first sample isL (1, tensor([932., 567.]))\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the class\n",
    "# play around with different *dataset_len* to get a better understanding of the output\n",
    "\n",
    "# Fix the random number generator\n",
    "torch.manual_seed(10)\n",
    "my_first_dataset = MyFirstDataset(X=X)\n",
    "\n",
    "# Access a sample from the dataset\n",
    "print(f'Length of the dataset is: {len(my_first_dataset)}'), \n",
    "print(f'The first sample isL {my_first_dataset[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b330450e",
   "metadata": {},
   "source": [
    "Let us now introduce the dataloader.   \n",
    "\n",
    "When we specify the batch size of 5, our 10 samples sets are in 2 batches. Notice the two tuples of *tensors*.  Go ahead and change the batch size to see how the output changes.  Try setting it at 3 for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa608b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f261ee8cb60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the \n",
    "my_first_dataloader = DataLoader(dataset=my_first_dataset, batch_size=5, num_workers=2, shuffle=False)\n",
    "my_first_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2532d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0, 1, 2, 3, 4]), tensor([[937., 405.],\n",
      "        [932., 567.],\n",
      "        [432., 705.],\n",
      "        [187.,  92.],\n",
      "        [321., 805.]])]\n",
      "[tensor([5, 6, 7, 8, 9]), tensor([[256., 773.],\n",
      "        [521., 210.],\n",
      "        [536., 833.],\n",
      "        [504., 610.],\n",
      "        [616.,  22.]])]\n"
     ]
    }
   ],
   "source": [
    "# Print out the batches\n",
    "for batch in my_first_dataloader:\n",
    "    print(batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef8eb4d",
   "metadata": {},
   "source": [
    "First tensor contains the index positions. This is why we see [0, 1, 2, 3, 4] in the first tensor. Second tensor is the actual value in X split across the two batches. Notice also if you were to re-run the for lop above, you would have the same results every time. This is because we set shuffle=False when we created the dataloader. \n",
    "\n",
    "We could simply set the dataloader shuffle=True and work with the default randomizer. Let us instead try this on our own. The default sampler uses a *SequentialSampler* as shown below.  \n",
    "\n",
    "### Step 3:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7373c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.sampler.SequentialSampler"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the default sampler \n",
    "type(my_first_dataloader.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3656a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is similar to the SequentialSampler directly\n",
    "from torch.utils.data import SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad39966d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.sampler.SequentialSampler at 0x7f2744a051f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see below we get the same output as before with the SequentialSampler\n",
    "seq_sampler = SequentialSampler(data_source=X)\n",
    "seq_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c3fb2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number: 0 has items: \n",
      "[tensor([5, 6, 7, 8, 9]), tensor([[256., 773.],\n",
      "        [521., 210.],\n",
      "        [536., 833.],\n",
      "        [504., 610.],\n",
      "        [616.,  22.]])]\n",
      "[tensor([0, 1, 2, 3, 4]), tensor([[937., 405.],\n",
      "        [932., 567.],\n",
      "        [432., 705.],\n",
      "        [187.,  92.],\n",
      "        [321., 805.]])]\n",
      "****************************************\n",
      "Batch number: 1 has items: \n",
      "[tensor([5, 6, 7, 8, 9]), tensor([[256., 773.],\n",
      "        [521., 210.],\n",
      "        [536., 833.],\n",
      "        [504., 610.],\n",
      "        [616.,  22.]])]\n",
      "[tensor([5, 6, 7, 8, 9]), tensor([[256., 773.],\n",
      "        [521., 210.],\n",
      "        [536., 833.],\n",
      "        [504., 610.],\n",
      "        [616.,  22.]])]\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "# Setup the dataloader again. This time use the sequential sampler\n",
    "X_loader= DataLoader(dataset=my_first_dataset, batch_size=5, sampler=seq_sampler)\n",
    "\n",
    "# Enumerate the batches\n",
    "# Similar to before, play around with the batch size to see how your output varies\n",
    "# This output is sequential just as the one above# Let us transition this shuffling the dataset\n",
    "for batch_idx, item in enumerate(X_loader):\n",
    "    print(f'Batch number: {batch_idx} has items: \\n{batch}')\n",
    "    print(item)\n",
    "    print('*'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b7cf1b",
   "metadata": {},
   "source": [
    "The results look much the same as we saw earlier.   \n",
    "\n",
    "Let us move to setting shuffle = True\n",
    "\n",
    "### Step 4:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58a7668f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.sampler.RandomSampler"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us instantiate the class once \n",
    "# This time, notice the *shuffle=True*\n",
    "\n",
    "X_loader= DataLoader(dataset=my_first_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "# if we look at the dataset type again\n",
    "# We see we are using the Random Sampler\n",
    "type(X_loader.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "635d9b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number: 0 has items: \n",
      "[tensor([5, 0, 8, 6, 2]), tensor([[256., 773.],\n",
      "        [937., 405.],\n",
      "        [504., 610.],\n",
      "        [521., 210.],\n",
      "        [432., 705.]])]\n",
      "****************************************\n",
      "Batch number: 1 has items: \n",
      "[tensor([9, 7, 4, 3, 1]), tensor([[616.,  22.],\n",
      "        [536., 833.],\n",
      "        [321., 805.],\n",
      "        [187.,  92.],\n",
      "        [932., 567.]])]\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "# Enumerate the batches.\n",
    "# Similar to before, play around with the batch size to see your output\n",
    "# Also run this a few times\n",
    "# The results should change every time\n",
    "# The order of the output should change every time you run this\n",
    "\n",
    "for batch_idx, batch in enumerate(X_loader):\n",
    "    print(f'Batch number: {batch_idx} has items: \\n{batch}')\n",
    "    print('*'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0156ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the shuffle=True is the same as using the RanomSampler\n",
    "from torch.utils.data import RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d57b987a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[937., 405.],\n",
       "        [932., 567.],\n",
       "        [432., 705.],\n",
       "        [187.,  92.],\n",
       "        [321., 805.],\n",
       "        [256., 773.],\n",
       "        [521., 210.],\n",
       "        [536., 833.],\n",
       "        [504., 610.],\n",
       "        [616.,  22.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the random sampler on X\n",
    "X_random_sampler = RandomSampler(X)\n",
    "X_dataset = MyFirstDataset(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86bf8017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index number: 0 batch index: tensor([3, 5, 0, 4, 7]) has item: \n",
      "tensor([[187.,  92.],\n",
      "        [256., 773.],\n",
      "        [937., 405.],\n",
      "        [321., 805.],\n",
      "        [536., 833.]])\n",
      "Index number: 1 batch index: tensor([6, 9, 8, 2, 1]) has item: \n",
      "tensor([[521., 210.],\n",
      "        [616.,  22.],\n",
      "        [504., 610.],\n",
      "        [432., 705.],\n",
      "        [932., 567.]])\n"
     ]
    }
   ],
   "source": [
    "# Setup another dataloader, using the raondom sampler \n",
    "X_loader = DataLoader(dataset=X_dataset, batch_size=5, sampler=X_random_sampler)\n",
    "for index, (batch_idx, batch) in enumerate(X_loader):\n",
    "    print(f'Index number: {index} batch index: {batch_idx} has item: \\n{batch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4aba30",
   "metadata": {},
   "source": [
    "We should now have a solid understanding of the role datasets and dataloader play in ensuring we do not run out of memory.\n",
    "\n",
    "### Lab Takeaways:  \n",
    "- As can be seen from above, we use the dataset to customize our data and the data loader to handle our data in batches.  \n",
    "- From above, if you play around the the *batch_size* you will notice the number of tuples change. For example, with batch size of two, we see two tuples above. \n",
    "- Notice the *tensor* appearing twice. Each one is a Tensor. \n",
    "- If you change the *batch_size* to 4, you will see we have everything returned because we have only four items in our length.\n",
    "- So the dataloader takes our full data returns it in batch sizes of our choice. Basically splitting it up into batch_size groups.\n",
    "\n",
    "With that understanding, we are ready to to use the dataset and dataloader to accept the main part of our data  .\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adversarial_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
