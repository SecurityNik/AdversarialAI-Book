{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2919451d",
   "metadata": {},
   "source": [
    "<img style=\"max-width:20em; height:auto;\" src=\"../graphics/A-Little-Book-on-Adversarial-AI-Cover.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52386086",
   "metadata": {},
   "source": [
    "Author: Nik Alleyne   \n",
    "Author Blog: https://www.securitynik.com   \n",
    "Author GitHub: github.com/securitynik   \n",
    "\n",
    "Author Other Books: [   \n",
    "\n",
    "            \"https://www.amazon.ca/Learning-Practicing-Leveraging-Practical-Detection/dp/1731254458/\",   \n",
    "            \n",
    "            \"https://www.amazon.ca/Learning-Practicing-Mastering-Network-Forensics/dp/1775383024/\"   \n",
    "        ]   \n",
    "\n",
    "\n",
    "This notebook ***(hash_enc_logging.ipynb)*** is part of the series of notebooks From ***A Little Book on Adversarial AI***  A free ebook released by Nik Alleyne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda2b85",
   "metadata": {},
   "source": [
    "### Hashing, Encryption and Logging For Our Models   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f96242e",
   "metadata": {},
   "source": [
    "### Lab Objectives:   \n",
    "- Establish various mechanisms for securing our models once deployed  \n",
    "- Leverage encryption for ensuring the privacy of our models  \n",
    "- Leverage Hashing to ensure integrity of our models   \n",
    "- Leverage continuous monitoring, to ensure we are able to detect what we cannot prevent\n",
    "\n",
    "With that in mind, let us get some data and create a simple model.  \n",
    "\n",
    "### Step 1:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f270358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us first start with import dotenv\n",
    "from dotenv import dotenv_values\n",
    "import hashlib\n",
    "\n",
    "import cryptography\n",
    "from cryptography.fernet import Fernet\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import onnxruntime\n",
    "from onnxruntime import InferenceSession\n",
    "import socket\n",
    "\n",
    "import getpass\n",
    "import sklearn\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.svm import LinearSVC\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d78fbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cryptography version used:  45.0.5\n",
      "Onnxruntime version used:  1.22.1\n",
      "Sklearn version used:  1.7.0\n"
     ]
    }
   ],
   "source": [
    "### Version of key libraries used  \n",
    "print(f'Cryptography version used:  {cryptography.__version__}')\n",
    "print(f'Onnxruntime version used:  {onnxruntime.__version__}')\n",
    "print(f'Sklearn version used:  {sklearn.__version__}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3541ec84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample X: \n",
      "[[ 3.67982584  4.68165164]\n",
      " [ 2.94713748  4.46116773]\n",
      " [ 4.32968132  5.64396726]\n",
      " [ 6.73488595 -9.38994773]\n",
      " [ 2.44301805  3.84652646]]\n",
      "Sample y: \n",
      "[1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Let us create a simple model for this problem.\n",
    "X, y = make_blobs(centers=2, random_state=10)\n",
    "print(f'Sample X: \\n{X[:5]}')\n",
    "print(f'Sample y: \\n{y[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5668691b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/linear_svc_clf.joblib\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# Just a simple model. Nothing important with LinearSVC\n",
    "clf = LinearSVC(random_state=10).fit(X, y)\n",
    "\n",
    "# Save the model to disk\n",
    "joblib.dump(value=clf, filename=r'/tmp/linear_svc_clf.joblib')\n",
    "\n",
    "# Verify the model was saved\n",
    "!ls /tmp/linear_svc_clf.joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fd8eba",
   "metadata": {},
   "source": [
    "With the model saved, let us setup our logger. In this case, we create a log file *securitynik_adversarial_ai.log* where we can write the interactions with our model. This file can also be forwarded to your SIEM or even analyzed locally, to understand the type of interactions being had with your models. \n",
    "\n",
    "### Step 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa392d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 22:44:23,647 SecurityNik_Adversarial_AI INFO     [*] Application startup: Hostname: SECURITYNIK-G14 / 127.0.1.1, Running as user: securitynik with uid: 1000 linux Platform\n"
     ]
    }
   ],
   "source": [
    "# Let's setup a logger\n",
    "# https://docs.python.org/3/howto/logging-cookbook.html\n",
    "# There are a couple of different approaches we can use here\n",
    "\n",
    "logger = logging.getLogger(name='SecurityNik_Adversarial_AI')\n",
    "logger.setLevel(level=logging.DEBUG)\n",
    "\n",
    "# Let's start this off with logging to a local file\n",
    "# you can even continue to use this with your syslog or some other tool to forward this file to a remote logging destination\n",
    "# Think about your SIEM for example.\n",
    "log_file_handler = logging.FileHandler(filename=r'/tmp/securitynik_adversarial_ai.log')\n",
    "log_file_handler.setLevel(level=logging.DEBUG)\n",
    "\n",
    "# Setup the console logger, if we wanted to write to the screen\n",
    "console_logger = logging.StreamHandler()\n",
    "console_logger.setLevel(level=logging.DEBUG)\n",
    "#logging.basicConfig(format='%(asctime)s %(clientip)-15s %(user)-8s %(message)s',  level=logging.INFO)\n",
    "\n",
    "# Log remotely. Your SIEM?\n",
    "remote_logger = logging.handlers.SysLogHandler(address=('127.0.0.1', 514), socktype=socket.SOCK_DGRAM)\n",
    "remote_logger.setLevel(level=logging.DEBUG)\n",
    "\n",
    "logger.addHandler(hdlr=log_file_handler)\n",
    "logger.addHandler(hdlr=console_logger)\n",
    "logger.addHandler(hdlr=remote_logger)\n",
    "\n",
    "# Setup a logging format  \n",
    "formatter = logging.Formatter(fmt='%(asctime)-15s %(name)-5s %(levelname)-8s %(message)s')\n",
    "log_file_handler.setFormatter(fmt=formatter)\n",
    "console_logger.setFormatter(fmt=formatter)\n",
    "\n",
    "# With this information if you know in you know that only specific sources within your org should be making predictions, \n",
    "# Then you can look for deviations from this source IP, user, UID and platform\n",
    "logger.info(msg=f'[*] Application startup: Hostname: {socket.gethostname()} / {socket.gethostbyaddr(socket.gethostname())[2][0]}, Running as user: {getpass.getuser()} with uid: {os.getuid()} {getpass.sys.platform} Platform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2422b99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-01 22:44:23,647 SecurityNik_Adversarial_AI INFO     [*] Application startup: Hostname: SECURITYNIK-G14 / 127.0.1.1, Running as user: securitynik with uid: 1000 linux Platform\n"
     ]
    }
   ],
   "source": [
    "# Take a peak into the log.\n",
    "# You should do this from your command line\n",
    "# We are doing it here for convenience.  \n",
    "!cat /tmp/securitynik_adversarial_ai.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e66201",
   "metadata": {},
   "source": [
    "To help with the encrypting and decrypting, we will use a library named cryptography. \n",
    "\n",
    "https://cryptography.io/en/latest/  \n",
    "\n",
    "### Step 3:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5417e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a function to encrypt the file\n",
    "def encrypt_file(model_file=None):\n",
    "    # Generate a key\n",
    "    enc_key = Fernet.generate_key()\n",
    "    fernet_enc = Fernet(key=enc_key)\n",
    "\n",
    "    # Open the file we would like to read\n",
    "    with open(file=model_file, mode='rb') as e_file:\n",
    "        clear_text = e_file.read()\n",
    "\n",
    "    # Perform the actual encryption\n",
    "    cipher_text = fernet_enc.encrypt(clear_text)\n",
    "\n",
    "    # Overwrite the file with the new encrypted data\n",
    "    with open(file=model_file, mode='wb') as e_file:\n",
    "        e_file.write(cipher_text)\n",
    "    \n",
    "    # Return the encryption key\n",
    "    return enc_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "702dbc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'ZqVhZqfSi28EqysvPSAnp8sp47YCMZjE2MU97W33Ksg='"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the encryption function\n",
    "# We are obviously assuming you have a correct file that you are pointing to\n",
    "# We could have done error checking above\n",
    "# However, we are keeping it simple\n",
    "encrypt_file(model_file=r'/tmp/linear_svc_clf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec657ab",
   "metadata": {},
   "source": [
    "Let us work on the integrity checking at this time via hashing. \n",
    "\n",
    "### Step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b480f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to hash a file\n",
    "def hash_file(model_file=None):\n",
    "    #print(f'Hashing file: {model_file}')\n",
    "\n",
    "    # Open the file to be hashed\n",
    "    with open(file=model_file, mode='rb') as hash_file:\n",
    "        sha_256_hash = hashlib.sha256(string=hash_file.read())\n",
    "\n",
    "    # Return the file hash\n",
    "    return sha_256_hash.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6568bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fa88efbda2cabe7c97cda75a6f3933e349c314823966e1107297be0d20f9c54d'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the hash function\n",
    "hash_file(model_file=r'/tmp/linear_svc_clf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92e464f",
   "metadata": {},
   "source": [
    "We put everything together now in one function.\n",
    "\n",
    "### Step 5:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b51e9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize the file. \n",
    "# Actually call the functions to encrypt and hash\n",
    "# We will also log this activity\n",
    "def hash_encrypt(model_file=None, env_path='/tmp/.env'):\n",
    "    # Define the path to the .env file\n",
    "    env_file_path = os.path.abspath(path=env_path)\n",
    "\n",
    "    # Check to see if the .env file exist in the current directory\n",
    "    if os.path.exists(path=env_file_path):\n",
    "        logger.info(msg='[*] Dot env file found')\n",
    "    else:\n",
    "        logger.warn(msg='[+] .env file not found. Creating it!')\n",
    "        open(file=env_file_path, mode='wt')\n",
    "\n",
    "    # Call our encrypt function\n",
    "    e_key = encrypt_file(model_file=model_file)\n",
    "\n",
    "    # Call our hash function\n",
    "    h_file = hash_file(model_file=model_file)\n",
    "\n",
    "    # Write the hash information to the .env file\n",
    "    with open(file=env_file_path, mode='wt') as e_file:\n",
    "        e_file.write(f'model_file_path={os.path.abspath(path=model_file)}\\n')\n",
    "        e_file.write(f'model_encryption_key={e_key}\\n')\n",
    "        e_file.write(f'model_sha_256_hash={h_file}\\n')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a99d4949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30831/1745664762.py:12: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  logger.warn(msg='[+] .env file not found. Creating it!')\n",
      "2025-08-01 22:44:24,075 SecurityNik_Adversarial_AI WARNING  [+] .env file not found. Creating it!\n"
     ]
    }
   ],
   "source": [
    "# Call the function to test\n",
    "hash_encrypt(model_file=r'/tmp/linear_svc_clf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "924224fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_file_path=/tmp/linear_svc_clf.joblib\n",
      "model_encryption_key=b'80w-niZUn6QZnPmmyA1nNHAw049xICN-Mknc-Ff59r4='\n",
      "model_sha_256_hash=906cab4bd6ec19335a98f982d51e33f1892cb8ad09bc6cbf7cea749dddd8990e\n"
     ]
    }
   ],
   "source": [
    "# If above went well, we should now be able to see into the .env file\n",
    "!cat /tmp/.env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fce769a",
   "metadata": {},
   "source": [
    "At this point, when the model is loaded, can validate its integrity and privacy by calling our functions. We can also log the interaction as expected. \n",
    "\n",
    "### Step 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51d0705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that you have the .env file populated\n",
    "# all you need to do is load the model and validate everything\n",
    "def load_model_make_prediction(model_file='', env_path=r'/tmp/.env'):\n",
    "    # Define the path to the .env file\n",
    "    env_values = dotenv_values(dotenv_path=os.path.abspath(path=env_path))\n",
    "    \n",
    "    # Validate the file is loading from the correct path\n",
    "    if model_file == env_values['model_file_path']:\n",
    "        logger.info(msg='[*] File path successfully validated ...')\n",
    "    else:\n",
    "        logger.warning(msg=f'[!] Model file **{model_file}** is being load from an unknown location')\n",
    "    \n",
    "    # Validate the hash of the encrypted file\n",
    "    if hash_file(model_file=model_file) == env_values['model_sha_256_hash']:\n",
    "        logger.info(msg='[*] Model File integrity successfully validate')\n",
    "    else:\n",
    "        logger.error(msg='[!] Exiting! File integrity check failed')\n",
    "        return\n",
    "    \n",
    "    # If the file hash was successful validated, then decrypt the file\n",
    "    # Notice the slicing at the end? This is because the result is stored as a bytes\n",
    "    # We need to remove the b' and final '\n",
    "    fernet_decrypt = Fernet(env_values['model_encryption_key'][2:-1])\n",
    "\n",
    "    try:\n",
    "        with open(file=model_file, mode='rb') as fp:\n",
    "            # Decrypt the model\n",
    "            loaded_model = fernet_decrypt.decrypt(fp.read())\n",
    "            logger.info(msg=f'[*] Successfully decrypted model file: {model_file}')\n",
    "                \n",
    "    except Exception as e:\n",
    "        # If an error is found then during decryption, catch the error\n",
    "        logger.error(msg=f'[!] An error occurred while decrypting the file. Exiting ...')\n",
    "        return\n",
    "\n",
    "    # if everything worked out, then make a prediction\n",
    "    logger.info(f'[*] Final Prediction: {clf.predict(X=X[:5])}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ed21f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 22:44:24,408 SecurityNik_Adversarial_AI INFO     [*] File path successfully validated ...\n",
      "2025-08-01 22:44:24,414 SecurityNik_Adversarial_AI INFO     [*] Model File integrity successfully validate\n",
      "2025-08-01 22:44:24,418 SecurityNik_Adversarial_AI INFO     [*] Successfully decrypted model file: /tmp/linear_svc_clf.joblib\n",
      "2025-08-01 22:44:24,424 SecurityNik_Adversarial_AI INFO     [*] Final Prediction: [1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Call the function to make the predictions\n",
    "load_model_make_prediction(model_file='/tmp/linear_svc_clf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "586bfcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-01 22:44:23,647 SecurityNik_Adversarial_AI INFO     [*] Application startup: Hostname: SECURITYNIK-G14 / 127.0.1.1, Running as user: securitynik with uid: 1000 linux Platform\n",
      "2025-08-01 22:44:24,075 SecurityNik_Adversarial_AI WARNING  [+] .env file not found. Creating it!\n",
      "2025-08-01 22:44:24,408 SecurityNik_Adversarial_AI INFO     [*] File path successfully validated ...\n",
      "2025-08-01 22:44:24,414 SecurityNik_Adversarial_AI INFO     [*] Model File integrity successfully validate\n",
      "2025-08-01 22:44:24,418 SecurityNik_Adversarial_AI INFO     [*] Successfully decrypted model file: /tmp/linear_svc_clf.joblib\n",
      "2025-08-01 22:44:24,424 SecurityNik_Adversarial_AI INFO     [*] Final Prediction: [1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Verify the file \n",
    "!cat /tmp/securitynik_adversarial_ai.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48382d9",
   "metadata": {},
   "source": [
    "### Takeaways:   \n",
    "- We were able to implement integrity, encryption and logging for our model   \n",
    "- These are critical components we need to consider when deploying our models  \n",
    "- We are here for adversarial AI purposes and thus we should understand the importance of these tasks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f6c551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adversarial_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
